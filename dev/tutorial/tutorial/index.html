<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tutorial · Scruff.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Scruff.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Getting Started</a></li><li class="is-active"><a class="tocitem" href>Tutorial</a><ul class="internal"><li><a class="tocitem" href="#What-Scruff-is-all-about"><span>What Scruff is all about</span></a></li><li><a class="tocitem" href="#Some-opening-examples"><span>Some opening examples</span></a></li><li><a class="tocitem" href="#Scruff-concepts"><span>Scruff concepts</span></a></li><li><a class="tocitem" href="#Sfuncs"><span>Sfuncs</span></a></li><li><a class="tocitem" href="#Operators"><span>Operators</span></a></li><li><a class="tocitem" href="#Models"><span>Models</span></a></li><li><a class="tocitem" href="#Networks"><span>Networks</span></a></li><li><a class="tocitem" href="#Algorithms"><span>Algorithms</span></a></li><li><a class="tocitem" href="#The-runtime"><span>The runtime</span></a></li><li><a class="tocitem" href="#Future-work"><span>Future work</span></a></li></ul></li><li><a class="tocitem" href="../examples/">Examples</a></li><li><span class="tocitem">Library</span><ul><li><a class="tocitem" href="../../lib/core/">Core</a></li><li><a class="tocitem" href="../../lib/sfuncs/">Stochastic Functions</a></li><li><a class="tocitem" href="../../lib/operators/">Operators</a></li><li><a class="tocitem" href="../../lib/models/">Models</a></li><li><a class="tocitem" href="../../lib/algorithms/">Algorithms</a></li><li><a class="tocitem" href="../../lib/utilities/">Utilities</a></li><li><a class="tocitem" href="../../lib/rtutils/">Runtime Utilities</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Tutorial</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Tutorial</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/charles-river-analytics/Scruff.jl/blob/develop/docs/src/tutorial/tutorial.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="The-Scruff-Tutorial"><a class="docs-heading-anchor" href="#The-Scruff-Tutorial">The Scruff Tutorial</a><a id="The-Scruff-Tutorial-1"></a><a class="docs-heading-anchor-permalink" href="#The-Scruff-Tutorial" title="Permalink"></a></h1><h2 id="What-Scruff-is-all-about"><a class="docs-heading-anchor" href="#What-Scruff-is-all-about">What Scruff is all about</a><a id="What-Scruff-is-all-about-1"></a><a class="docs-heading-anchor-permalink" href="#What-Scruff-is-all-about" title="Permalink"></a></h2><p>Scruff is a flexible framework for building AI systems. Although its roots are in probabilistic programming, it is not strictly speaking a probabilistic programming language. Instead, it is a framework for combining models of different kinds and reasoning with them. Scruff provides three main features:</p><ol><li><p>The ability to combine different kinds of models and reason with them using an algorithm in an integrated way. Scruff decomposes the representation of models from algorithms that work with them using operators. Any representation (the scruff word is sfunc (stochastic function, pronounced &quot;essfunk&quot;)) that implements the operators can appear in algorithms. Using this approach enables us to generalize algorithms like belief propagation and importance sampling that have traditionally been applied to probabilistic models. A given sfunc does not have to support all operators and algorithms can use sfuncs in the appropriate way. For example, it is legal to have an sfunc that you can&#39;t sample from, which would not be possible in a typical probabilistic programming language. </p></li><li><p>A flexible framework for inference using these representations. Scruff distinguishes between the notion of a variable, which represents a value that can vary over time, and an instance of that variable, which represents its value at a particular time. In Scruff, variables are associated with models, which determine which sfunc to use for specific instances. There is no requirement that instances follow a regular time pattern; if the model supports it, instances can appear at any time interval. It is also possible to combine instances appearing at different time intervals, for example slowly changing and rapidly changing variables. Scruff also provides the ability to perform iterative inference, where beliefs about instances are refined through repeated computation.</p></li><li><p>Composition, reuse, and experimentation with different models, sfuncs, and algorithms. Scruff comes with an extensible and structured library of models, sfuncs, operators, and algorithms, making it easy to mix and match or extend with your own. For example, it is possible to implement alternative versions of an operators for an sfunc side by side and choose between them manually, or even automatically based on the characteristics of the specific instance. Another example is to compare accuracy and runtime between different time granularities on a variable by variable basis. Finally, as sfunc composition is highly structured, it is possible to experiment with specific sfunc choices in a systematic way.</p></li></ol><p>The name Scruff derives from the old debates in AI between the neats and the scruffies. Neats believed that unless systems were developed in a coherent framework, it would be impossible to scale development of AI systems to complex real-world problems. Scruffies believed that real-world problems require a variety of techniques that must be combined as best as possible, and forcing everything into a neat framework would hinder progress. We believe that both camps have an element of the truth, and Scruff is an attempt to provide the best of both worlds. Scruff&#39;s philosophy is to allow a variety of representations and implementations to coexist side by side, and not every algorithm can be applied to every representation. However, they all coexist in a clean, well-defined and organized framework that enables scalable development of models and systems.</p><h2 id="Some-opening-examples"><a class="docs-heading-anchor" href="#Some-opening-examples">Some opening examples</a><a id="Some-opening-examples-1"></a><a class="docs-heading-anchor-permalink" href="#Some-opening-examples" title="Permalink"></a></h2><p>We start this tutorial with three examples illustrating idiomatic use of Scruff and some of its capabilities. These examples can be found in the <code>docs/examples</code> folder (they are also linked by the <a href="../examples/#Examples">Examples</a> page).</p><h3 id="Instant-reasoning"><a class="docs-heading-anchor" href="#Instant-reasoning">Instant reasoning</a><a id="Instant-reasoning-1"></a><a class="docs-heading-anchor-permalink" href="#Instant-reasoning" title="Permalink"></a></h3><p>Our first example, found in <a href="https://github.com/p2t2/Scruff.jl/tree/main/docs/examples/novelty_example.jl"><code>novelty_example.jl</code></a> is about detecting and characterizing novel behaviors. In this example, a behavior is simply something that generates a real number, but the example extends to more interesting kinds of behavior. The example shows how to create sfuncs, models, variables, and networks, and how to reason with them. We call this an instant reasoning example because there is no temporal element.</p><p>We begin with some imports:</p><pre><code class="language-julia hljs">    using Scruff
    using Scruff.Models
    using Scruff.SFuncs
    using Scruff.Algorithms</code></pre><p>Since we&#39;re going to run experiments with different setups, we define a NoveltySetup data structure.</p><pre><code class="language-julia hljs">    struct NoveltySetup
        known_sfs::Vector{Dist{Float64}}
        known_probs::Vector{Float64}
        novelty_prob::Float64
        novelty_prior_mean::Float64
        novelty_prior_sd::Float64
        novelty_sd::Float64
    end</code></pre><p>Here, <code>known_sfs</code> is a vector of known behaviors, each one represented by a sfunc. In particular, each behavior is a <code>Dist{Float64}</code>, meaning it is an unconditional distribution over <code>Float64</code>. <code>known_probs</code> is the probabilities of the known behaviors, assuming the behavior is not novel, while <code>novelty_prob</code> is the probability that the behavior is novel. A novel behavior has a mean and standard deviation. The mean is drawn from a normal distrbution with mean <code>novelty_prior_mean</code> and standard deviation <code>novelty_prior_sd</code>. The novel behavior&#39;s own standard deviation is given by <code>novelty_sd</code>.</p><p>We now define a function that takes a setup and returns a network. Since observations are also part of the network, this function also takes the number of observations as an argument.</p><pre><code class="language-julia hljs">    function novelty_network(setup::NoveltySetup, numobs::Int)::InstantNetwork</code></pre><p>This function begins by defining some variables. For the first variable, we&#39;ll go through the steps in detail. For the remaining variables, we&#39;ll use some syntactic sugar. The first variable represents the known behavior. Defining it takes three steps: creating the sfunc, defining the model, and associating it with a variable. Much of Scruff&#39;s power comes from separating these three concepts. However, for the common case where we want to do all three of these things together, we provide syntactic sugar.</p><p>First we create the sfunc:</p><pre><code class="language-julia hljs">    known_sf = Cat(setup.known_sfs, setup.known_probs)</code></pre><p>This defines <code>known_sf</code> to be a categorical distribution, where the choices are provided by <code>setup.known_sfs</code> and the probabilities are specified by <code>setup.known_probs</code>. The important idea is that this distribution is an entity of its own, irrespective of specific variables that are related using it. An sfunc is similar to the mathematical concept of a function. It describes a relationship between variables that is not necessarily determinisitic. In mathematics, we can define concepts like function composition, which operate on the functions directly and don&#39;t require the notion of variables. Similarly in Scruff, there are a variety of ways to compose and combine sfuncs. Furthermore, we can have sfuncs be values in models as well, which enables higher-order probabilistic programming. In fact, in this example, <code>known_sf</code> represents a categorical distribution over sfuncs.</p><p>After creating the sfunc, we create a model using the sfunc:</p><pre><code class="language-julia hljs">    known_model = SimpleModel(known_sf)</code></pre><p>A model describes which sfunc to generate for a variable in different situations. In general, the sfunc representing a variable&#39;s distribution can change depending on the situation, such as the time of instantiation of the variable and times of related instances. Here, we just have a <code>SimpleModel</code> that always returns the same sfunc, but later we will have more interesting models.</p><p>The third step is to create a variable and associate it with the model. This is achieved by calling the model with the variable name (a symbol) as argument:</p><pre><code class="language-julia hljs">    known = known_model(:known)</code></pre><p>We now have the Julia variable <code>known</code> whose value is a Scruff variable with the name <code>:known</code> associated with <code>known_model</code>. If you just want to create a variable with a <code>SimpleModel</code> for a specific sfunc, you can use syntactic sugar as follows:</p><pre><code class="language-julia hljs">    known = Cat(setup.known_sfs, setup.known_probs)()(:known)</code></pre><p>When we call the sfunc with zero arguments, we create a <code>SimpleModel</code> with the sfunc; then, when we apply that model to the variable name, we create the variable. In the rest of this example, we will use this form. Let&#39;s create some more variables:</p><pre><code class="language-julia hljs">    is_novel = Flip(setup.novelty_prob)()(:is_novel)
    novelty_mean = Normal(setup.novelty_prior_mean, setup.novelty_prior_sd)()(:novelty_mean)
    novelty = Det(Tuple{Float64}, Dist{Float64}, m -&gt; Normal(m[1], setup.novelty_sd))()(:novelty)
    behavior = If{Dist{Float64}}()()(:behavior)</code></pre><p><code>is_novel</code> represents whether the behavior is novel or known. This variable will be true with probability <code>setup.novelty_prob</code>. <code>novelty_mean</code> represents the mean of the novel behavior using a normal distribuiton whose mean and standard deviation are given by the setup. <code>novelty</code> uses an sfunc called <code>Det</code>, which stands for &quot;deterministic&quot;. It describes a determinstic relationship between one or more arguments and a result. When you define a <code>Det</code>, you have to give the Julia compiler hints about the input and output types of the function. The input type of an sfunc in Scruff is always a tuple of arguments, so in this case it is a tuple of a single <code>Float64</code> argument. Our intent is for this input to represent the mean of the novel behavior; however, as we have discussed, sfuncs exist independently of the variables to which they will be applied. The connection to the novelty mean will be made later. The output of the <code>Det</code> is an unconditional distribution of type <code>Dist{Float64}</code>. This is another example of an sfunc outputting an sfunc representing a behavior. We now have two such sfuncs: <code>known</code> and <code>novelty</code>. We are ready to choose the actual behavior, using the <code>sf_choice</code> variable. The sfunc for <code>sf_choice</code> is defined by <code>If{Dist{Float64}}()</code>. Unlike most probabilistic programming languages, which almost always provide an <code>if</code> control flow concept that choose between specific alternatives based on a test, Scruff&#39;s <code>If</code> describes the general process of choosing between two alternatives using a Boolean test. In this example, the intent is to choose between <code>novelty</code> and <code>known</code> based on <code>is_novel</code>. These connections will be made later. Note that the type of value produced by the <code>If</code> is a type parameter, which in this case is again a <code>Dist{Float64}</code>, representing the actual behavior that gets chosen.</p><p>Now that we have these variables, we are ready to start building the connections described in the previous paragraph. We will build the ingredients to an <code>InstantNetwork</code>, which are a list of variables, and a <code>VariableGraph</code>, representing a dictionary from variables to their parents.</p><pre><code class="language-julia hljs">    variables = [known, is_novel, novelty_mean, novelty, behavior]
    graph = VariableGraph(novelty =&gt; [novelty_mean], behavior =&gt; [is_novel, novelty, known])</code></pre><p>Finally, we need to add observations, which is done in a flexible way depending on the number of observations.</p><pre><code class="language-julia hljs">    for i in 1:numobs
        obs = Generate{Float64}()()(obsname(i))
        push!(variables, obs)
        graph[obs] = [behavior]
    end</code></pre><p>For each observation, we create a variable whose name is given by the utility function <code>obsname(i)</code>. The sfunc is <code>Generate{Float64}</code>. <code>Generate{Float64}</code> is a second-order sfunc  that takes as input a <code>Dist{Float64}</code> and generates a <code>Float64</code> from it.  Thus, each observation is an independent sample from the behavior.  We add the observation to the <code>variables</code> vector and make its parents the <code>behavior</code> variable.</p><p>Finally, we create the instant network and return it.</p><pre><code class="language-julia hljs">    return InstantNetwork(variables, graph)</code></pre><p>Now that we&#39;ve built the network, we&#39;re ready to run some experiments.  Here&#39;s the code to run an experiment. It takes as arguments the setup, the vector of observations, and the <code>InstantAlgorithm</code> to use (an <code>InstantAlgorithm</code> is an algorithm run on an <code>InstantNetwork</code>; it does not handle dynamics).</p><pre><code class="language-julia hljs">    function do_experiment(setup::NoveltySetup, obs::Vector{Float64}, alg::InstantAlgorithm)
        net = novelty_network(setup, length(obs))
        evidence = Dict{Symbol, Score}()
        for (i,x) in enumerate(obs)
            evidence[obsname(i)] = HardScore(x)
        end
        runtime = Runtime(net)
        infer(alg, runtime, evidence)

        is_novel = get_node(net, :is_novel)
        novelty_mean = get_node(net, :novelty_mean)
        println(&quot;Probability of novel = &quot;, probability(alg, runtime, is_novel, true))
        println(&quot;Posterior mean of novel behavior = &quot;, mean(alg, runtime, novelty_mean))
    end</code></pre><p><code>do_experiment</code> first creates the network and then builds up the <code>evidence</code> data structure, which is a dictionary from variable names to scores. In Scruff, a <code>Score</code> is an sfunc  with no outputs that specifies a number for each value of its input. A <code>HardScore</code> is a score that assigns the value 1 to its argument and 0 to everything else. The next step is to create a runtime using the network. The runtime holds all the information needed by the inference algorithm to perform its computations and answer queries. We then call <code>infer</code>, which does the actual work. Once <code>infer</code> completes, we can answer some queries. To answer a query, we need handles to the variables we want to use, which is done using the <code>get_node</code> method. Finally, the <code>probability</code> and <code>mean</code> methods give us the answers we want.</p><p>The examples next defines some setups and an observation list.</p><pre><code class="language-julia hljs">    function setup(generation_sd::Float64, prob_novel::Float64)::NoveltySetup
        known = [Normal(0.0, generation_sd), Normal(generation_sd, generation_sd)]
        return NoveltySetup(known, [0.75, 0.25], prob_novel, 0.0, 10.0, generation_sd)
    end
    setup1 = setup(1.0, 0.1)
    setup2 = setup(4.0, 0.1)
    obs = [5.0, 6.0, 7.0, 8.0, 9.0]</code></pre><p>In <code>setup1</code>, behaviors have a smaller standard deviation, while in <code>setup2</code>,  the standard deviation is larger. We would expect the posterior probability of <code>is_novel</code> to be higher for <code>setup1</code> than <code>setup2</code> because it is harder to explain the observations with known behaviors when they have a small standard deviation.</p><p>Finally, we run some experiments. </p><pre><code class="language-julia hljs">    println(&quot;Importance sampling&quot;)
    println(&quot;Narrow generation standard deviation&quot;)
    do_experiment(setup1, obs, LW(1000))
    println(&quot;Broad generation evidence&quot;)
    do_experiment(setup2, obs, LW(1000))

    println(&quot;\nBelief propagation&quot;)
    println(&quot;Narrow generation standard deviation&quot;)
    do_experiment(setup1, obs, ThreePassBP())
    println(&quot;Broad generation evidence&quot;)
    do_experiment(setup2, obs, ThreePassBP())

    println(&quot;\nBelief propagation with larger ranges&quot;)
    println(&quot;Narrow generation standard deviation&quot;)
    do_experiment(setup1, obs, ThreePassBP(25))
    println(&quot;Broad generation evidence&quot;)
    do_experiment(setup2, obs, ThreePassBP(25))</code></pre><p><code>LW(1000)</code> creates a likelihood weighting algorithm that uses 1000 particles, while <code>ThreePassBP()</code> creates a non-loopy belief propagation  algorithm. In this example, the network has no loops so using a non-loopy BP algorithm is good. However, BP needs to discretize the continuous variables, which most of the variables in this example are. With no arguments, it uses the default number of bins (currently 10). <code>ThreePassBP(25)</code> creates a BP algorithm that uses 25 bins. </p><p>The first time you run this example, it might take a while. Julia uses just in time (JIT) compilation, so the first run can involve a lot of compilation overhead. But subsequent runs are very fast. When you run this example, it produces output like this:</p><pre><code class="nohighlight hljs">julia&gt; include(&quot;docs/examples/novelty_example.jl&quot;)
Importance sampling
Narrow generation standard deviation
Probability of novel = 1.0
Posterior mean of novel behavior = 7.334211013744095
Broad generation evidence
Probability of novel = 0.1988404327033635
Posterior mean of novel behavior = 0.631562661691411

Belief propagation
Narrow generation standard deviation
Probability of novel = 1.0
Posterior mean of novel behavior = 7.71606183538526
Broad generation evidence
Probability of novel = 0.2534439250343668
Posterior mean of novel behavior = 1.7131189737655137

Belief propagation with larger ranges
Narrow generation standard deviation
Probability of novel = 1.0
Posterior mean of novel behavior = 6.979068103646596
Broad generation evidence
Probability of novel = 0.2591460898562207
Posterior mean of novel behavior = 1.7363865329521413</code></pre><p>We see that as expected, the probability of novel is much higher with narrow generation standard deviation than with broad. All three algorithms have similar qualitative results. Running the experiment a few times shows that the importance sampling method has relatively high variance. We also see that the estimate of the posterior mean changes significantly as we add more values to the ranges of variables for the BP method.</p><h3 id="Incremental-reasoning"><a class="docs-heading-anchor" href="#Incremental-reasoning">Incremental reasoning</a><a id="Incremental-reasoning-1"></a><a class="docs-heading-anchor-permalink" href="#Incremental-reasoning" title="Permalink"></a></h3><p>Building on the last point, our next example, found in  <a href="https://github.com/p2t2/Scruff.jl/tree/main/docs/examples/novelty_lazy.jl"><code>novelty_lazy.jl</code></a>, uses Scruff&#39;s  incremental inference capabilities to gradually increase the range sizes of the  variables to improve the estimates. We&#39;re going to use an algorithm called Lazy Structured Factored Inference (LSFI). LSFI repeatedly calls an <code>InstantAlgorithm</code> (in this case variable elimination) on more and more refined versions of the network. Refinement generally takes two forms: Expanding recursive networks to a greater depth,  and enlarging the ranges of continuous variables. Our example only has the latter refinement. When expanding recursive networks, LSFI can produce lower and upper bounds to query answers at each iteration. This capability is less useful for range refinement, but our code needs to handle the bounds.</p><p>The network and setups are just as in <code>novelty_example.jl</code>. The code for running an experiment is similar in structure but has some new features.</p><pre><code class="language-julia hljs">    function do_experiment(setup, obs)
        net = novelty_network(setup, length(obs))
        is_novel = get_node(net, :is_novel)
        novelty_mean = get_node(net, :novelty_mean)
        evidence = Dict{Symbol, Score}()
        for (i,x) in enumerate(obs)
            evidence[obsname(i)] = HardScore(x)
        end

        alg = LSFI([is_novel, novelty_mean]; start_size = 5, increment = 5)
        runtime = Runtime(net)
        prepare(alg, runtime, evidence)

        for i = 1:10
            println(&quot;Range size: &quot;, alg.state.next_size)
            refine(alg, runtime)
            is_novel_lb = probability_bounds(alg, runtime, is_novel, [false, true])[1]
            println(&quot;Probability of novel = &quot;, is_novel_lb[2])
            println(&quot;Posterior mean of novel behavior = &quot;, mean(alg, runtime, novelty_mean))
        end
    end</code></pre><p>As before, the code creates the network, gets handles of some variables, and fills the evidence data structure. In this case, we use <code>LSFI</code>. When creating an <code>LSFI</code> algorithm, we need to tell it which variables we want to query, which are <code>is_novel</code> and <code>novelty_mean</code>. <code>LSFI</code> also has some optional arguments. In this example, we configure it to have a starting range size of 5 and increment the range size by 5 on each refinement. Before running inference, we need to call <code>prepare(alg, runtime, evidence)</code>. Then we go through ten steps of refinement. We can get the range size of the next refinement using <code>alg.state.next_size</code> (we only use this for printing).  Refinement is done through a call to <code>refine(alg, runtime)</code>. We then need to do a little more work than before to get the answers to queries because of the probabilities bounds. <code>probability_bounds(alg, runtime, is_novel, [false, true])</code> returns lower and upper bounds  as 2-element vectors of probabilities of <code>false</code> and <code>true</code>. As discussed earlier, these bounds are not true bounds in the case of range refinement, so we just pick the first one, and then pick the second value, corresponding to <code>true</code>, out of that vector. The <code>mean</code> method already arbitrarily uses the lower bounds so we don&#39;t have to do any work there.</p><p>Running this example produces a result like:</p><pre><code class="nohighlight hljs">Lazy Inference
Narrow generation standard deviation
Range size: 5
Probability of novel = 1.0
Posterior mean of novel behavior = 5.0
Range size: 10
Probability of novel = 1.0
Posterior mean of novel behavior = 5.000012747722526
Range size: 15
Probability of novel = 1.0
Posterior mean of novel behavior = 5.000012747722526
Range size: 20
Probability of novel = 1.0
Posterior mean of novel behavior = 5.000012747722526
Range size: 25
Probability of novel = 1.0
Posterior mean of novel behavior = 5.000012747722526
Range size: 30
Probability of novel = 1.0
Posterior mean of novel behavior = 5.000012747722526
Range size: 35
Probability of novel = 1.0
Posterior mean of novel behavior = 5.000012747722526
Range size: 40
Probability of novel = 1.0
Posterior mean of novel behavior = 5.000012747722526
Range size: 45
Probability of novel = 1.0
Posterior mean of novel behavior = 5.000012747722526
Range size: 50
Probability of novel = 1.0
Posterior mean of novel behavior = 5.000012747722526

Broad generation evidence
Range size: 5
Probability of novel = 0.23525574698998955
Posterior mean of novel behavior = 1.1750941076530532
Range size: 10
Probability of novel = 0.19825748797545847
Posterior mean of novel behavior = -0.11214142944113853
Range size: 15
Probability of novel = 0.19745646974840933
Posterior mean of novel behavior = -0.11168834527313051
Range size: 20
Probability of novel = 0.19283490006948978
Posterior mean of novel behavior = 0.3602757973718763
Range size: 25
Probability of novel = 0.1926826680899825
Posterior mean of novel behavior = 0.35995765581210176
Range size: 30
Probability of novel = 0.1825284089501074
Posterior mean of novel behavior = 1.1318032244818
Range size: 35
Probability of novel = 0.18251757269528399
Posterior mean of novel behavior = 1.1294239567980586
Range size: 40
Probability of novel = 0.18251757269528404
Posterior mean of novel behavior = 1.1294239567980597
Range size: 45
Probability of novel = 0.18251757269528404
Posterior mean of novel behavior = 1.1294239567980597
Range size: 50
Probability of novel = 0.18251757269528404
Posterior mean of novel behavior = 1.1294239567980597</code></pre><p>Looking at this output, we see that the narrow generation standard deviation case is easy and the algorithm  quickly converges. However, in the broad generation standard deviation case, we see that there is a big change in the posterior mean of novel behavior between range size 25 and 30. This is to do with the way values in the range are generated. As the range size is increased, values further and further away from the prior mean are created. At range size 30, a value is introduced that has low prior but fits the data well, which increases the posterior mean.</p><h3 id="Dynamic-reasoning"><a class="docs-heading-anchor" href="#Dynamic-reasoning">Dynamic reasoning</a><a id="Dynamic-reasoning-1"></a><a class="docs-heading-anchor-permalink" href="#Dynamic-reasoning" title="Permalink"></a></h3><p>Our final example <a href="https://github.com/p2t2/Scruff.jl/tree/main/docs/examples/novelty_filtering.jl"><code>novelty_filtering.jl</code></a> riffs on the novelty theme to use dynamic reasoning. Now, observations are received over time at irregular intervals. A behavior now represents the velocity of an object moving in one dimension, starting at point 0.0. This example moves away from the higher-order sfuncs but introduces some new kinds of models.</p><p>The setup is similar but slightly different:</p><pre><code class="language-julia hljs">    struct NoveltySetup
        known_velocities::Vector{Float64}
        known_probs::Vector{Float64}
        novelty_prob::Float64
        novelty_prior_mean::Float64
        novelty_prior_sd::Float64
        transition_sd::Float64
        observation_sd::Float64
    end</code></pre><p>We have known velocities and their probabilities, the probability of novelty, and the mean and standard deviation of the novel velocity. We also have the standard deviation of the transition and observation models.</p><p>Because the observations appear irregularly and not at fixed time steps, we are going to use a <code>VariableTimeModel</code> to represent the position of the object.  To create a <code>VariableTimeModel</code>, we need to create a new type that inherits from  <code>VariableTimeModel</code> and implement the methods <code>make_initial</code>, which creates the sfunc for the initial time step, and <code>make_transition</code>, which creates the sfunc at each time step at which we instantiate the variable. </p><pre><code class="language-julia hljs">    struct PositionModel &lt;: VariableTimeModel{Tuple{}, Tuple{Float64, Float64}, Float64} 
        setup::NoveltySetup
    end
    function make_initial(::PositionModel, ::Float64)::Dist{Float64}
        return Constant(0.0)
    end
    function make_transition(posmod::PositionModel, parenttimes::Tuple{Float64, Float64}, time::Float64)::SFunc{Tuple{Float64, Float64}, Float64}
        function f(pair)  
            (prevval, velocity) = pair
            Normal(prevval + t * velocity, t * posmod.setup.transition_sd)
        end
        t = time - parenttimes[1]
        return Chain(Tuple{Float64, Float64}, Float64, f)
    end</code></pre><p><code>make_initial</code> simply returns <code>Constant(0.0)</code>, meaning that the object always starts at position 0.0 with no uncertainty. Because the amount of time between instantiations is variable, <code>make_transition</code> takes as argument a vector of times of the previous instantiation of its parents, as well as the current time.  It uses these times to determine exactly what the transition model should be. Here, it computes the time <code>t</code> between the current time and the previous instantiation of the first parent, which we will later connect to the position variable. So <code>t</code> represents the time since the last instantiation of the position variable. <code>make_transition</code> uses the <code>Chain</code> sfunc, which takes parent values and applies  a Julia function to produce the sfunc used to generate the value of the <code>Chain</code>. In this case, once we make the connections, the <code>Chain</code> will take the previous value of  the position and the velocity and create a <code>Normal</code> sfunc whose mean and standard deviation depend on <code>t</code>, as well as the standard deviation of the transition model in the setup. This Normal is then used to generate the current position. This code is a little sophisticated, but the ability to create variable time models and perform  asynchronous dynamic reasoning is a powerful feature of Scruff.</p><p>The rest of the example is simpler and we won&#39;t go over it in full detail. We do introduce the <code>StaticModel</code>, which represents a variable whose value is generated at the beginning of a run and never changes.  <code>StaticModel</code> is implemented as a <code>VariableTimeModel</code> where the transition function is  the identify function. Also, the <code>observation</code> variable uses a <code>SimpleModel</code>, because it is generated afresh  instantaneously every time it is instantiated. It is defined to be a normal whose mean is the position and whose standard deviation is given by the setup. This is implemented using the <code>LinearGaussian</code> sfunc.</p><p>A <code>DynamicNetwork</code> uses two variable graphs for the initial and transition steps. In this example, all the logic of choosing the behavior happens in the initial graph, while the position logic and its dependence on previous position and velocity is in the transition graph. The transition graph also contains copy edges for the static variables.</p><pre><code class="language-julia hljs">    variables = [known_velocity, is_novel, novel_velocity, velocity, position, observation]
    initial_graph = VariableGraph(velocity =&gt; [is_novel, novel_velocity, known_velocity], observation =&gt; [position])
    transition_graph = VariableGraph(known_velocity =&gt; [known_velocity], is_novel =&gt; [is_novel], novel_velocity =&gt; [novel_velocity], velocity =&gt; [velocity], position =&gt; [position, velocity], observation =&gt; [position])</code></pre><p>We&#39;ll show the <code>do_experiment</code> implementation in detail because it illustrates how  asynchronous inference is performed.</p><pre><code class="language-julia hljs">    function do_experiment(setup::NoveltySetup, obs::Vector{Tuple{Float64, Float64}}, alg::Filter)
        net = novelty_network(setup, length(obs))
        runtime = Runtime(net, 0.0) # Set the time type to Float64 and initial time to 0
        init_filter(alg, runtime)

        is_novel = get_node(net, :is_novel)
        velocity = get_node(net, :velocity)
        observation = get_node(net, :observation)

        for (time, x) in obs
            evidence = Dict{Symbol, Score}(:observation =&gt; HardScore(x))
            println(&quot;Observing &quot;, x, &quot; at time &quot;, time)
            # At a minimum, we need to include query and evidence variables in the filter step
            filter_step(alg, runtime, Variable[is_novel, velocity, observation], time, evidence)

            println(&quot;Probability of novel = &quot;, probability(alg, runtime, is_novel, true))
            println(&quot;Posterior mean of velocity = &quot;, mean(alg, runtime, velocity))
        end
    end</code></pre><p>After creating the network, we create a runtime. The call to <code>Runtime</code> takes a second argument that not only sets the initial time but also established the type used to represent time, which is <code>Float64</code>. We first need to initialize the filter with <code>init_filter</code> which runs the initial time step, and get handles  to the variables we care about. Our observation sequence is a vector (sorted by increasing time) of (time, value) pairs. For each such pair, we create the evidence at that time point. Then we run a <code>filter_step</code>. Besides the algorithm and runtime, the filter step takes a vector of variables to instantiate, the current time, and the evidence. There is no need to instantiate all the variables at every filter step. At a minimum, we need to instantiate evidence variables as well as any variables we want to query. Since we&#39;re going to query <code>is_novel</code> and <code>velocity</code>, we&#39;ll have to instantiate those using their copy transition model. However, we never need to instantiate the <code>known_velocity</code> and <code>novel_velocity</code> variables after the initial time step. Finally, we can answer queries about the current state in a similar way to the other examples.</p><p>For the experiments, we create a setup and two sequences of observations, the second of which is harder to explain with known behaviors.</p><pre><code class="language-julia hljs">    # Known velocities are 0 and 1, novelty has mean 0 and standard deviation 10
    setup = NoveltySetup([0.0, 1.0], [0.7, 0.3], 0.1, 0.0, 10.0, 1.0, 1.0)
    obs1 = [(1.0, 2.1), (3.0, 5.8), (3.5, 7.5)] # consistent with velocity 2
    obs2 = [(1.0, 4.9), (3.0, 17.8), (3.5, 20.5)] # consistent with velocity 6</code></pre><p>We then use <code>CoherentPF(1000)</code> as the filtering algorithm. Current filtering algorithms in  Scruff combine an instantiation method that creates a window with an underlying  <code>InstantAlgorithm</code> to infer with the window. Available window creation methods include synchronous, asynchronous, and coherent. Coherent is similar to asynchronous except that it adds variables to the instantiation to maintain coherence of parent-child relationships. In this example, it ensures that the position variable is also instantiated, not just the query and evidence variables. <code>CoherentPF(1000)</code> describes a particle filter that uses a coherent window creator and an importance sampling algorithm with 1000 particles. The example also shows how you can similarly create a coherent BP algorithm. However, BP does not work well in models with static variables because dependencies between the static variables are lost between filtering steps.</p><p>Running this example produces output like the following for the particle filter:</p><pre><code class="nohighlight hljs">Particle filter
Smaller velocity
Observing 2.1 at time 1.0
Probability of novel = 0.0351642575352557
Posterior mean of velocity = 0.5411884423148781
Observing 5.8 at time 3.0
Probability of novel = 0.057222570825582145
Posterior mean of velocity = 0.8705507592898075
Observing 7.5 at time 3.5
Probability of novel = 0.08166159149240186
Posterior mean of velocity = 1.007810909419299

Larger velocity
Observing 4.9 at time 1.0
Probability of novel = 0.6741688102988623
Posterior mean of velocity = 3.6150131656907174
Observing 17.8 at time 3.0
Probability of novel = 1.0
Posterior mean of velocity = 5.898986723263269
Observing 20.5 at time 3.5
Probability of novel = 1.0
Posterior mean of velocity = 5.86994402484129</code></pre><h2 id="Scruff-concepts"><a class="docs-heading-anchor" href="#Scruff-concepts">Scruff concepts</a><a id="Scruff-concepts-1"></a><a class="docs-heading-anchor-permalink" href="#Scruff-concepts" title="Permalink"></a></h2><p>The central concepts of Scruff are:</p><ul><li>Sfuncs, or stochastic functions, which represent mathematical relationships between variables</li><li>Operators, which define and implement computations on sfuncs</li><li>Models, which specify how to create sfuncs in different situations</li><li>Variables, which represent domain entities that may take on different values at different times</li><li>Networks, which consist of variables and the dependencies between them</li><li>Instances, which represent a specific instantiation of a variable at a point in time</li><li>Algorithms, which use operations to perform computations on networks</li><li>Runtimes, which manage instances as well as information used by algorithms</li></ul><h2 id="Sfuncs"><a class="docs-heading-anchor" href="#Sfuncs">Sfuncs</a><a id="Sfuncs-1"></a><a class="docs-heading-anchor-permalink" href="#Sfuncs" title="Permalink"></a></h2><p>An <code>SFunc</code> has an input type, which is a tuple, and an output type. Although the name implies probabilistic relationships, in principle sfuncs can be used to represent any kind of information. The representation of an sfunc is often quite minimal, with most of the detail contained in operators. The general type is <code>SFunc{I &lt;: Tuple, O}</code>.</p><h3 id="Dists"><a class="docs-heading-anchor" href="#Dists">Dists</a><a id="Dists-1"></a><a class="docs-heading-anchor-permalink" href="#Dists" title="Permalink"></a></h3><p>A <code>Dist{O}</code> is an <code>SFunc{Tuple{}, O}</code>. In other words, a <code>Dist</code> represents an unconditional distribution with no parents. Examples of <code>Dist</code> include <code>Constant</code>, <code>Cat</code>, <code>Flip</code>, and <code>Normal</code>.</p><h3 id="Scores"><a class="docs-heading-anchor" href="#Scores">Scores</a><a id="Scores-1"></a><a class="docs-heading-anchor-permalink" href="#Scores" title="Permalink"></a></h3><p>A <code>Score{I}</code> is an <code>SFunc{Tuple{I}, Nothing}</code>. In other words, it takes a single value of  type <code>I</code>, and rather than produce an output, it just associates information (typically a likelihood) with its input. A <code>Score</code> is often used to represent evidence. Examples of <code>Score</code> include <code>HardScore</code> (only a single value allowed),  <code>SoftScore</code> (allows multiple values), <code>LogScore</code> (similar to <code>SoftScore</code> but represented in log form), <code>FunctionalScore</code> (score is computed by applying a function to the input), <code>NormalScore</code> (representing a normal distribution around a value),  and <code>Parzen</code> (mixture of normal scores).</p><h3 id="Conditional-Sfuncs"><a class="docs-heading-anchor" href="#Conditional-Sfuncs">Conditional Sfuncs</a><a id="Conditional-Sfuncs-1"></a><a class="docs-heading-anchor-permalink" href="#Conditional-Sfuncs" title="Permalink"></a></h3><p>Scruff provides a range of ways to construct sfuncs representing conditional distributions. These are organized in a type hierarchy:</p><p>— <code>Invertible</code>: deterministic functions with a deterministic inverse, enabling efficient operator implementations<br/>— <code>Det</code>: deterministic functions without an inverse<br/>   └ <code>Switch</code>: chooses between multiple incoming choices based on first argument<br/>      └ <code>LinearSwitch</code>: first argument is an integer and switch chooses corresponding result<br/>      └ <code>If</code>: first argument is a Boolean and switch chooses appropriate other argument <br/>— <code>Conditional</code>: abstract representation of sfuncs that use first arguments to create sfunc to apply to other arguments<br/>   └ <code>LinearGaussian</code>: sfunc representing normal distribution whose mean is a linear function of the parents<br/>   └ <code>Table</code>: abstract representation of sfuncs that use first arguments to choose sfunc to apply from a table<br/>      └ <code>DiscreteCPT</code>: discrete conditional probability table<br/>      └ <code>CLG</code>: conditional linear Gaussian model: table of linear Gaussians depending on discrete parents<br/>— <code>Separable</code>: Mixture of <code>DiscreteCPT</code> to decompose dependency on many parents, enabling efficient operator implementations<br/></p><h3 id="Compound-Sfuncs"><a class="docs-heading-anchor" href="#Compound-Sfuncs">Compound Sfuncs</a><a id="Compound-Sfuncs-1"></a><a class="docs-heading-anchor-permalink" href="#Compound-Sfuncs" title="Permalink"></a></h3><p>Compound sfuncs can be though of as a construction kit to compose more complex sfuncs out of simpler ones. These also include some higher-order sfuncs.</p><ul><li><code>Generate</code>: generate a value from its sfunc argument</li><li><code>Apply</code>: similar to generate, but the sfunc argument is applied to another argument</li><li><code>Chain</code>: apply a function to the arguments to produce an sfunc, then generate a value from the sfunc</li><li><code>Mixture</code>: choose which sfunc to use to generate values according to a probability distribution</li><li><code>Serial</code>: connect any number of sfuncs in series</li><li><code>NetworkSFunc</code>: connect any number of sfuncs according to a graph</li><li><code>Expander</code>: apply a function to the arguments to produce a network that can be used recursively</li></ul><h2 id="Operators"><a class="docs-heading-anchor" href="#Operators">Operators</a><a id="Operators-1"></a><a class="docs-heading-anchor-permalink" href="#Operators" title="Permalink"></a></h2><p>An operator represents a computation that can be performed on an sfunc. An operator is not just a function or a method.  It is an object that can contain information (such as configuration instructions) and can be reasoned about, for example to specify policies to choose between alternative implementations. Operators consist of definitions, created using <code>@op_def</code>, which specify type information, and implementation, created using <code>@impl</code>.</p><p>Here are some of the most commonly used operators:</p><ul><li><code>cpdf(sf, parent_values, x)</code> returns the conditional probability of <code>x</code> given <code>parent_values</code></li><li><code>logcpdf(sf, parent_values, x)</code></li><li><code>sample(sf, parent_values)</code></li><li><code>get_score(sf, x)</code> returns the score associated with <code>x</code></li><li><code>get_log_score(sf, x)</code></li><li><code>support(sf, parent_ranges, target_size, current)</code> computes a range of values for the sfunc given that the parents have values in <code>parent_ranges</code>. <code>target_size</code> is guidance as to the size of support to produce, which does not need to be obeyed precisely. <code>current</code> is a list of values that should be included in the support, which is useful for iterative refinement.</li></ul><p>The above operators will be implemented specifically for a given sfunc. In general, an sfunc does not need to support all operators. For example, typically only a <code>Score</code> will support <code>get_score</code> and <code>get_log_score</code>.  Some sfuncs will not be able to support sampling or density computation, and that&#39;s okay. For example, if an sfunc doesn&#39;t support <code>sample</code>, but it does support <code>cpdf</code>, and that sfunc is always observed, it can be used in likelihood weighting. If it is not always observed, it won&#39;t be usable in importance sampling but it might be usable in BP. The goal is to enable representations to be used as much as possible, rather than require everything to work uniformly. This is where the scruffiness of Scruff comes in.</p><p>There are a variety of operators useful in BP and related algorithms. Most of these have default implementations that work for sfuncs in general and you don&#39;t need to worry about implementing them for a new sfunc.  The two that need to be implemented specifically are:</p><ul><li><code>compute_pi(sf, range, parent_ranges, parent_pi_messages)</code>, which integrates over the parents to produce a distribution over the value of the instance associated with the sfunc. The <code>parent_pi_messages</code>, as well as the computed distribution, are represented as <code>Dist</code>s, rather than vectors or anything specific, which enables great flexibility in implementation.</li><li><code>send_lambda(sf, lambda, range, parent_ranges, parent_pi_messages, parent_index)</code> computes the lambda message to be sent to the parent specified by <code>parent_index</code>.</li></ul><p>Once these two operators are implemented for an sfunc, the sfunc can participate in any BP algorithm. Furthermore, sfuncs at the leaves of a network do not need to implement <code>compute_pi</code>. For example, <code>send_lambda</code> can be implemented for a feedforward neural network, enabling it to be included in a general BP inference process.</p><h2 id="Models"><a class="docs-heading-anchor" href="#Models">Models</a><a id="Models-1"></a><a class="docs-heading-anchor-permalink" href="#Models" title="Permalink"></a></h2><p>One of Scruff&#39;s key features is the ability to reason flexibly about variables that vary over time, and, in future, space. This is accomplished using models, which specify how to make the sfunc to use for a particular instance of a variable. Currently, Scruff&#39;s <code>models</code> library is relatively small. We plan to expand it in future, for example with learning models that improve their sfuncs based on experience.</p><p>Here is the current type hierarchy of models</p><p>—<code>InstantModel</code>: for a variable with no dependencies on previous time points<br/>  └ <code>TimelessInstantModel</code>: an <code>InstantModel</code> where the sfunc also does not depend on the current time<br/>  └ <code>SimpleModel</code>: a <code>TimelessInstantModel</code> in which the sfunc to use is passed in the definition of the model<br/>— <code>FixedTimeModel</code>: a model for a variable that depends on its own state at the previous time point and other variables at the current time point. The delta between the current and previous time point must be a fixed <code>dt</code>.<br/>  └ <code>TimelessFixedTimeModel</code>: a <code>FixedTimeModel</code> in which the sfunc does not depend on the current time<br/>  └ <code>HomogenousModel</code>: a <code>TimelessFixedTimeModel</code> in which the initial and transition sfuncs are passed in the definition of the model<br/>— <code>VariableTimeModel</code>: a model for a variable whose transition sfunc depends on the time intervals since the instantiations of its parents (which may be at different times)<br/>  └ <code>StaticModel</code>: a model for a variable whose value is set in the initial time point and never changes afterward<br/></p><h2 id="Networks"><a class="docs-heading-anchor" href="#Networks">Networks</a><a id="Networks-1"></a><a class="docs-heading-anchor-permalink" href="#Networks" title="Permalink"></a></h2><p>Networks contains nodes, which are either variables or placeholders. Unlike variables, placeholders are not associated with models. Rather, they are intended to indicate values that should be received from outside the network. They are particularly useful for recursive reasoning, as well as dynamic inference.</p><p>An <code>InstantNetwork</code> is created with two to four arguments:</p><ul><li>A vector of variables</li><li>A variable graph, associating variables with their parents. If a variable has no parents, it can be omitted from the graph.</li><li>(Optional) A vector of placeholders, which defaults to empty</li><li>(Optional) A vector of outputs, which should be a subset of the variables, again defaults to empty. This is intended to support providing an interface to networks that enables internal nodes and embedded networks to be eliminated, but this feature is not used yet.</li></ul><p>A <code>DynamicNetwork</code> is created with three to six arguments</p><ul><li>A vector of variables</li><li>An initial variable graph</li><li>A transition variable graph</li><li>(Optional) A vector of initial placeholders, defaults to empty</li><li>(Optional) A vector of transition placeholders, defaults to empty</li><li>(Optional) A vector of outputs, defaults to empty</li></ul><h2 id="Algorithms"><a class="docs-heading-anchor" href="#Algorithms">Algorithms</a><a id="Algorithms-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithms" title="Permalink"></a></h2><p>Scruff&#39;s algorithms library is structured so that more complex algorithms can be built out of simpler algorithms. The basic algorithms are instances of <code>InstantAlgorithm</code> and run on an <code>InstantNetwork</code>. Scruff currently provides the following hierarchy of instant algorithms. We intend to expand this list over time:</p><p>— <code>InstantAlgorithm</code>: abstract type for which implementations must implement the <code>infer</code> method<br/>  └ <code>Importance</code>: general importance sampling framework<br/>    └ <code>Rejection</code>: rejection sampling<br/>    └ <code>LW</code>: likelihood weighting<br/>    └ Custom proposal: An importance sampling algorithm can be made from a proposal scheme using <code>make_custom_proposal</code>. A proposal scheme specifies alternative sfuncs to use as alternatives to the prior distribution for specific sfuncs<br/>  └ <code>BP</code>: general belief propagation framework<br/>    └ <code>ThreePassBP</code>: non-loopy belief propagation<br/>    └ <code>LoopyBP</code><br/>  └ <code>VE</code>: variable elimination</p><p>Scruff provides iterative algorithms that gradually improve their answers over time. These follow the following hierarchy:</p><p>— <code>IterativeAlgorithm</code>: abstract type for which implementations must implement the <code>prepare</code> and <code>refine</code> methods<br/>  └ <code>IterativeSampler</code>: iterative algorithm that uses a sampler to increase the number of samples each refinement. For example, you can use <code>IterativeSampler(LW(1000))</code> to use a likelihood weighting algorithm that adds 1,000 more samples on each call to <code>refine</code>.<br/>  └ <code>LazyInference</code>: an algorithm that expands the recursion depth and ranges of variables on each call to <code>refine</code> and then invokes an <code>InstantAlgorithm</code><br/>    └ <code>LSFI</code>: a <code>LazyInference</code> algorithm that uses variable elimination as its instant algorithm</p><p>For filtering, Scruff provides the general <code>Filter</code> class, for which implementations must implement the <code>init_filter</code> and <code>filter_step</code> methods. All current filter implementations in Scruff derive from <code>WindowFilter</code>, where, on each call to <code>filter_step</code>, the algorithm first creates an <code>InstantNetwork</code> representing a window and then invokes an <code>InstantAlgorithm</code>. To create a <code>WindowFilter</code>, you choose a windowing method from <code>SyncWindow</code>, <code>AsyncWindow</code>, and <code>CoherentWindow</code>, and specify the instant algorithm to use. For example, Scruff provides the following constructor for asynchronous BP:</p><pre><code class="nohighlight hljs">AsyncBP(range_size = 10, T = Float64) = WindowFilter(AsyncWindow{T}(), ThreePassBP(range_size))</code></pre><p>Once algorithms have been run, queries can be answered using a uniform interface. This includes methods like <code>marginal</code>, <code>joint</code>, <code>probability</code> (which could be the probability of a specific value or the probability of a predicate), <code>expectation</code>, <code>mean</code>, and <code>variance</code>. As usual, not all algorithms need implement all queries.</p><p>When you implement a new algorithm, you can specify how to answer queries using a standard <code>answer</code> method. Take a look at algorithm implementations to see how this works.</p><h2 id="The-runtime"><a class="docs-heading-anchor" href="#The-runtime">The runtime</a><a id="The-runtime-1"></a><a class="docs-heading-anchor-permalink" href="#The-runtime" title="Permalink"></a></h2><p>Unless you are implementing a new algorithm, you can largely ignore details of the runtime after you have created it, as everything happens under the hood. In general, the responsibilities of the runtime are to:</p><ul><li>Instantiate variables and associate them with the correct instance parents and sfunc</li><li>Identify the appropriate instances of variables at different point in time</li><li>Store and retrieve values associated with instances</li><li>Store and retrieve algorithm state across multiple invocations (e.g., using <code>refine</code>)</li><li>Manage passing of messages between variables</li></ul><h2 id="Future-work"><a class="docs-heading-anchor" href="#Future-work">Future work</a><a id="Future-work-1"></a><a class="docs-heading-anchor-permalink" href="#Future-work" title="Permalink"></a></h2><p>Future work in Scruff will follow five main lines:  developing more extensive libraries, including integration of other frameworks; developing a larger suite of algorithms using compositional methods; developing a more flexible framework of networks and recursive models;  creating spatial and spatiotemporal models with the same flexibility as current temporal models; and operators for performance characterization and optimization. We welcome contributions from the user community. If any of these items catches your interest, let us know and we will be happy to help with design and development.</p><h3 id="Larger-libraries-and-integration-of-other-frameworks"><a class="docs-heading-anchor" href="#Larger-libraries-and-integration-of-other-frameworks">Larger libraries and integration of other frameworks</a><a id="Larger-libraries-and-integration-of-other-frameworks-1"></a><a class="docs-heading-anchor-permalink" href="#Larger-libraries-and-integration-of-other-frameworks" title="Permalink"></a></h3><p>Scruff&#39;s current library, particularly of SFuncs, is fairly minimal, and needs to be extended to provide a fully functional probabilistic programming framework. Our intent is not to write sfuncs ourselves, but rather to wrap existing implementations wherever possible. An immediate goal is to wrap <code>Distributions.jl</code>, while will provide a wide range of <code>Dist</code> sfuncs. We also want to integrate with other probabilistic programming frameworks in Julia, such as Gen.</p><p>In addition, the ability to use data-driven models that don&#39;t support sampling but do support inference is central to Scruff. We want to develop a library of such models, again by integrating with existing frameworks and wrapping with appropriate observations. Algorithms also need to be modified to take advantage of such models.</p><h3 id="More-algorithms"><a class="docs-heading-anchor" href="#More-algorithms">More algorithms</a><a id="More-algorithms-1"></a><a class="docs-heading-anchor-permalink" href="#More-algorithms" title="Permalink"></a></h3><p>It is important that algorithms in Scruff are well-structured and compositional. The algorithms developed so far are a starter set that have been carefully designed with this philosophy. Noticable by its absence is MCMC, which is common in many probabilistic programming frameworks. Gibbs sampling can be implemented as a message passing algorithm and fits well with the current framework. Metropolis-Hastings and reversible jump algorithms will take more thought, but experience with other  probabilistic programming languages should show how to implement them in a consistent, compositional way.</p><p>A very natural next step is to generalize our algorithms to use other semirings besides aum-product. Again, this should happen in a compositional way. It should be possible to say something like <code>with_semiring(semiring, algorithm)</code> and have all computations in operators invoked by the algorithm drawn from the appropriate semiring. If we do this, it will be natural to write learning algorithms like EM and decision-making algorithms using maximum  expected utility using our instant algorithms. This will lead to powerful combinations. Would anyone like asynchronous online EM using BP?</p><p>Similarly, BP is just one example of a variational method. We want to expand BP into a more general compositional variational inference library. Finally, we want to generalize our elimination methods to employ conditioning as well as elimination.</p><h3 id="More-flexible-networks-and-recursion"><a class="docs-heading-anchor" href="#More-flexible-networks-and-recursion">More flexible networks and recursion</a><a id="More-flexible-networks-and-recursion-1"></a><a class="docs-heading-anchor-permalink" href="#More-flexible-networks-and-recursion" title="Permalink"></a></h3><p>The ability for networks to contain other networks is critical to structured, modular, representations as well as efficient inference through encapsulation and conditional compilation. In addition, the ability to generate contained networks stochastically supports open universe modeling.  Scruff currently supports these capabilities through Expanders. However, Expanders were an early addition to Scruff and are not integrated all that well in the most recent Scruff development. NetworkSFuncs are better integrated, but do not currently support containment and recursion. We want to align Expanders and NetworkSFuncs to provide more general structured and recursive networks.</p><h3 id="Spatially-flexible-models"><a class="docs-heading-anchor" href="#Spatially-flexible-models">Spatially flexible models</a><a id="Spatially-flexible-models-1"></a><a class="docs-heading-anchor-permalink" href="#Spatially-flexible-models" title="Permalink"></a></h3><p>Scruff currently has a flexible representation of variables that vary over time, but not of variables that vary over space, or space and time together. We want to provide spatiotemporal networks with the same flexibility as current DynamicNetworks. Moving beyond spatial models, we also want to create a framework for reasoning about variables that vary across graphs, such as social networks.</p><h3 id="Performance-Characterization-and-Optimization"><a class="docs-heading-anchor" href="#Performance-Characterization-and-Optimization">Performance Characterization and Optimization</a><a id="Performance-Characterization-and-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Characterization-and-Optimization" title="Permalink"></a></h3><p>Scruff&#39;s design is intended to enable reasoning about performance characteristics of operators and to support algorithms making decisions about which operators to use. Multiple operator implementations can exist side by side for given sfuncs and algorithms can use policies to decide which ones to use. This capability is currently only exercised in very rudimentary ways. We want to take advantage of this capability to provide a wide set of performance characteristics and intelligent algorithms that use them.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Getting Started</a><a class="docs-footer-nextpage" href="../examples/">Examples »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Wednesday 15 May 2024 18:49">Wednesday 15 May 2024</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
