var documenterSearchIndex = {"docs":
[{"location":"lib/core/#scruff_core","page":"Core","title":"Scruff","text":"","category":"section"},{"location":"lib/core/","page":"Core","title":"Core","text":"CurrentModule = Scruff","category":"page"},{"location":"lib/core/","page":"Core","title":"Core","text":"    Modules = [Scruff]","category":"page"},{"location":"lib/core/#Scruff.BELIEF","page":"Core","title":"Scruff.BELIEF","text":"BELIEF\n\nThe constant key used to store belief for a specific variable instance\n\n\n\n\n\n","category":"constant"},{"location":"lib/core/#Scruff.EVIDENCE","page":"Core","title":"Scruff.EVIDENCE","text":"EVIDENCE\n\nThe constant key used to store evidence for a specific variable instance\n\n\n\n\n\n","category":"constant"},{"location":"lib/core/#Scruff.INTERVENTION","page":"Core","title":"Scruff.INTERVENTION","text":"INTERVENTION\n\nThe constant key used to store interventions for a specific variable instance\n\n\n\n\n\n","category":"constant"},{"location":"lib/core/#Scruff.Node","page":"Core","title":"Scruff.Node","text":"Node{O} = Union{Placeholder{O}, Variable{I,J,O} where {I,J}}\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.Dist","page":"Core","title":"Scruff.Dist","text":"Dist{T} = SFunc{Tuple{}, T}\n\nAdditional supported operators\n\nmake_factors\nsend_lambda\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.DynamicNetwork","page":"Core","title":"Scruff.DynamicNetwork","text":"DynamicNetwork{I,J,O} <: Network{I,J,O}\n\nA network that can transition over time.   See Network for the type parameters.\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.DynamicRuntime","page":"Core","title":"Scruff.DynamicRuntime","text":"struct DynamicRuntime <: Runtime\n\nA runtime that represents a network whose variables take on many instances at different times T.\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.Env","page":"Core","title":"Scruff.Env","text":"struct Env\n\nHolds all external state of a Runtime.  The Env supports the following methods:\n\nget_state(env::Env) :: Dict{Symbol, Any}\nhas_state(env::Env, key::Symbol) :: Bool\nget_state(env::Env, key::Symbol)\nset_state!(env::Env, key::Symbol, value)\ndelete_state!(env::Env, key::Symbol)\nclear_state!(env::Env)\nclone(env::Env)\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.Instance","page":"Core","title":"Scruff.Instance","text":"Instance{O}\n\nAn abstract base type for variable and placeholder instances.\n\nThis is instance can have values associated with it in the runtime. O is the output type of the node.\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.InstantNetwork","page":"Core","title":"Scruff.InstantNetwork","text":"struct InstantNetwork{I,J,O} <: Network{I,Nothing,O}\n\nA network that only supports initial models.  The Nothing in the supertype shows that there is no transition to another time.\n\nSee Network for the type parameters\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.InstantRuntime","page":"Core","title":"Scruff.InstantRuntime","text":"struct InstantRuntime <: Runtime\n\nA runtime that represents a network whose variables take on a single instance.  As a convenience, the following methods create an InstantRuntime:\n\nRuntime()\nRuntime(net :: InstantNetwork)\nRuntime(net :: DynamicNetwork)\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.Model","page":"Core","title":"Scruff.Model","text":"Model{I, J, O} <: ValueTyped{O}\n\nSupertype for all Scruff models. The model represents a variable that varies over time and has output type O. The model may return an initial sfunc with input type I using make_initial, which takes the current time as argument, and a transition sfunc with input type J using make_transition, which takes both the parent times (a tuple of times of the same length as J) and the current time as arguments. These two functions need to be defined for every sfunc.\n\nType parameters\n\nI: the input type to the SFunc returned by the model's make_initial function \nJ: the input type to the SFunc used during the make_trasition function call\nO: the actual type of the variables represented by this model\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.Network","page":"Core","title":"Scruff.Network","text":"abstract type Network{I,J,O}\n\nCollects variables, with placeholders for inputs, and defined outputs, along with up to two directed graphs for initial and transition.  Must implement get_nodes, get_outputs, get_initial_graph, get_transition_graph (which returns a VariableGraph)\n\nFor the type parameters, see the underlying Model class for the mapped Variables.\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.Placeholder","page":"Core","title":"Scruff.Placeholder","text":"Placeholder{O} <: ValueTyped{O}\n\nA type for typing Scruff variables that do not reference models\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.PlaceholderInstance","page":"Core","title":"Scruff.PlaceholderInstance","text":"PlaceholderInstance\n\nAn instance of placeholder node at time.  This instance has no sfunc, but can still take  values in the runtime.\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.Runtime","page":"Core","title":"Scruff.Runtime","text":"abstract type Runtime\n\nA struct that contains the state of the compute graph. This code makes the assumption that values are associated with instances but messages are passed between variables and applied to the relevant instances later.  It has to be this way because the receiving instance might not exist at the time the message is sent.\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.SFunc","page":"Core","title":"Scruff.SFunc","text":"abstract type SFunc{I<:Tuple, O}\n\nA Stochastic Function type with input variables defined by I and output type O.   This is an abstract representation for a collection of operators with the same  input and output types.\n\nAll sfuncs have the following operators defined:\n\ncompute_lambda\ncompute_bel\nsend_pi\noutgoing_pis\noutgoing_lambdas\n\nSFunc also has both the operators cpdf and logcpdf defined in terms of the other.  All sfuncs should implement one or the other of these operators.\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.Score","page":"Core","title":"Scruff.Score","text":"Score{I} = SFunc{Tuple{I}, Nothing}\n\nScore supports two (2) operators:  get_score and get_log_score.  get_log_score is defined, by default, using get_score.  Every subtype of Score must implement get_score.\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.ValueTyped","page":"Core","title":"Scruff.ValueTyped","text":"abstract type ValueTyped{O}\n\nSupertype for typing all Scruff Variables; O is the  actual type of the variable\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.Variable","page":"Core","title":"Scruff.Variable","text":"mutable struct Variable{I,J,O} <: ValueTyped{O}\n\nA Variable describes the (time-series) of some set of random values. It must be named, described by a model, and references to the model inputs must be defined.\n\nFor the type variables, see Model\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.VariableGraph","page":"Core","title":"Scruff.VariableGraph","text":"VariableGraph = Dict{Node, Vector{Node}}\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.VariableInstance","page":"Core","title":"Scruff.VariableInstance","text":"VariableInstance\n\nAn instance of variable node at time.   sf is an sfunc generated from  the variable's model.\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.VariableParentTimeOffset","page":"Core","title":"Scruff.VariableParentTimeOffset","text":"VariableParentTimeOffset = Set{Pair{Node, Node}}\n\nRepresents whether a child-parent pair of nodes is time-offset; if they are time-offset, they will be in this set.\n\n\n\n\n\n","category":"type"},{"location":"lib/core/#Scruff.complete_graph!-Tuple{Vector{<:Variable}, Dict{Node, Vector{Node}}}","page":"Core","title":"Scruff.complete_graph!","text":"complete_graph!(variables::Vector{<:Variable}, graph::VariableGraph)\n\nPopulate the graph with v=>Node[] for all variables not in the graph. \n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.current_instance-Tuple{InstantRuntime, Node}","page":"Core","title":"Scruff.current_instance","text":"current_instance(runtime::InstantRuntime, node::Node)\ncurrent_instance(runtime::DynamicRuntime, node::Node)\n\nReturns the current (last) instance for the given runtime and node; this method will throw an exception if there is no current instance for the given node\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.current_time-Union{Tuple{DynamicRuntime{T}}, Tuple{T}} where T","page":"Core","title":"Scruff.current_time","text":"current_time(runtime::Runtime) -> T\n\nReturns the currently set time of the given Runtime\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.delete_value!-Tuple{Runtime, Instance, Symbol}","page":"Core","title":"Scruff.delete_value!","text":"delete_value!(runtime::Runtime{T}, instance::Instance, key::Symbol) where {T}\n\nDeletes the mapping for the given instance and key in the runtime and returns it\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.ensure_all!","page":"Core","title":"Scruff.ensure_all!","text":"ensure_all!(runtime::InstantRuntime, time=0) :: Dict{Symbol, Instance}\nensure_all!(runtime::DynamicRuntime, time = current_time(runtime)) :: Dict{Symbol, Instance}\n\nInstantiate all the variables in the network at the given time and returns them as a dict from variable names to their corresponding instance; the default time is the current time of the runtime in unix time.\n\n\n\n\n\n","category":"function"},{"location":"lib/core/#Scruff.ensure_instance!-Union{Tuple{O}, Tuple{Runtime, Node{O}}, Tuple{Runtime, Node{O}, Any}} where O","page":"Core","title":"Scruff.ensure_instance!","text":"ensure_instance!(runtime::Runtime{T}, node::Node{O}, time::T = current_time(runtime))::Instance{O} where {O,T}\n\nReturns an instance for the given variable at the given time, either by using an existing one or creating a new one.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_all_instances-Tuple{DynamicRuntime, Variable}","page":"Core","title":"Scruff.get_all_instances","text":"get_all_instances(runtime::DynamicRuntime, variable::Variable)\nget_all_instances(runtime::InstantRuntime, variable::Variable)\n\nReturns all instances in the runtime for the given variable, in order, as a Vector{Instance}.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_belief-Tuple{Runtime, Instance}","page":"Core","title":"Scruff.get_belief","text":"get_belief(runtime::Runtime, inst::Instance)\n\nReturns the last posted belief for the given instance; this will return nothing if no belief has been posted\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_definition-Tuple{VariableInstance}","page":"Core","title":"Scruff.get_definition","text":"get_definition(i::VariableInstance)::D where {D<:ValueTyped}\n\nGet the instance's variable's underlying model.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_evidence-Tuple{Runtime, Instance}","page":"Core","title":"Scruff.get_evidence","text":"get_evidence(runtime::Runtime, inst::Instance)\n\nReturns the last posted evidence for the given instance; this will return nothing if no evidence has been posted\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_initial_children-Tuple{Network, Node}","page":"Core","title":"Scruff.get_initial_children","text":"get_initial_children(n::Network, var::Node)::Vector{Node}\n\nReturns a list of the initial child nodes in the network from the network's initial graph (i.e. the return graph from getinitialgraph(network)).   \n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_initial_parents-Tuple{Network, Node}","page":"Core","title":"Scruff.get_initial_parents","text":"get_initial_parents(n::Network, node::Node)::Vector{Node}\n\nReturns a list of the initial parent nodes in the network from the network's initial graph (i.e. the return graph from getinitialgraph(network)).\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_instance-Union{Tuple{T}, Tuple{DynamicRuntime{T}, Node, T}} where T","page":"Core","title":"Scruff.get_instance","text":"function get_instance(runtime::DynamicRuntime{T}, node::Node, t::T)::Instance\n\nReturns instance for the given variable at time T; throws an error if no such instance exists.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_intervention-Tuple{Runtime, Instance}","page":"Core","title":"Scruff.get_intervention","text":"get_intervention(runtime::Runtime, inst::Instance)\n\nReturns the last posted intervention for the given instance; this will return nothing if no intervention has been posted\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_model-Tuple{VariableInstance}","page":"Core","title":"Scruff.get_model","text":"get_model(i::VariableInstance)::D where {D<:ValueTyped}\n\nGet the instance's variable's underlying model.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_name-Tuple{Instance}","page":"Core","title":"Scruff.get_name","text":"get_name(i::Instance)::Symbol\n\nGet the name of the instance's node.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_node-Tuple{Instance}","page":"Core","title":"Scruff.get_node","text":"get_node(i::Instance)::Node\n\nGet the instance's node, whether it is a placeholder or a variable.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_node-Tuple{Network, Symbol}","page":"Core","title":"Scruff.get_node","text":"get_node(n::Network, name::Symbol)::Union{Node, Nothing}\n\nReturns the node with the given name, or nothing.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_sfunc-Tuple{VariableInstance}","page":"Core","title":"Scruff.get_sfunc","text":"get_sfunc(i::VariableInstance)::SFunc\n\nGet the instance's sfunc.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_time-Tuple{Instance}","page":"Core","title":"Scruff.get_time","text":"get_time(i::Instance)\n\nGet the instance's time.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_transition_children-Tuple{Network, Node}","page":"Core","title":"Scruff.get_transition_children","text":"get_transition_children(n::Network, var::Node)::Vector{Node}\n\nReturns a list of transitioned child nodes in the network from the network's  transition graph (i.e. the return graph from gettransitiongraph(network))    \n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_transition_parents-Tuple{Network, Node}","page":"Core","title":"Scruff.get_transition_parents","text":"get_transition_parents(n::Network, node::Node)::Vector{Node}\n\nReturns a list of transitioned parent nodes in the network from the network's  transition graph (i.e. the return graph from gettransitiongraph(network))\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.get_value-Tuple{Runtime, Instance, Symbol}","page":"Core","title":"Scruff.get_value","text":"get_value(runtime::Runtime, instance::Instance, key::Symbol)\n\nGet the value on an instance for the given key; this will throw an exception if the instance does not contain the given key\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.has_instance","page":"Core","title":"Scruff.has_instance","text":"has_instance(runtime::DynamicRuntime, node::Node, time = current_time(runtime))\nhas_instance(runtime::InstantRuntime, node::Node)\n\nReturns true if the given node has an instance in the given runtime at a time greater than or equal to the given time.\n\n\n\n\n\n","category":"function"},{"location":"lib/core/#Scruff.has_previous_instance-Tuple{DynamicRuntime, Node}","page":"Core","title":"Scruff.has_previous_instance","text":"has_previous_instance(runtime::DynamicRuntime, node::Node)\n\nChecks if the specified node has an instance prior to the current one.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.initialize_algorithm-Tuple{Function, Runtime}","page":"Core","title":"Scruff.initialize_algorithm","text":"initialize_algorithm(alg_fun::Function, runtime::Runtime)\n\nInitializes the given algorithm's Runtime.  By default, this does nothing.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.input_type-Union{Tuple{Type{<:SFunc{I, O}}}, Tuple{O}, Tuple{I}} where {I, O}","page":"Core","title":"Scruff.input_type","text":"input_type(::Type{<:SFunc{I,O}}) where {I,O}\ninput_type(::SFunc{I,O}) where {I,O}\n\nReturn the input type (i.e. I) of the SFunc\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.instantiate!","page":"Core","title":"Scruff.instantiate!","text":"instantiate!(runtime::InstantRuntime,variable::Variable,time = 0)\ninstantiate!(runtime::InstantRuntime,placeholder::Placeholder,time = 0)\ninstantiate!(runtime::DynamicRuntime{T}, node::Node,time::T = current_time(runtime))::Instance where {T}\n\nInstantiate and return an instance for the given runtime at the given time; the default time is the current time of the runtime in unix time (an Int64). For an InstantRuntime,  there is only a single instance for each variable.\n\n\n\n\n\n","category":"function"},{"location":"lib/core/#Scruff.instantiate-Tuple{Model, Symbol}","page":"Core","title":"Scruff.instantiate","text":"instantiate(model::Model, name::Symbol)\n\nCreate a new Variable with the given name for the given model.  Every Model instance is also a function that, given a Symbol, will call  this method.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.latest_instance_before-Union{Tuple{T}, Tuple{DynamicRuntime{T}, Node, T, Bool}} where T","page":"Core","title":"Scruff.latest_instance_before","text":"latest_instance_before(runtime::DynamicRuntime{T}, node::Node, t::T, allow_equal::Bool) :: Union{Instance, Nothing} where T\n\nReturn the latest instance of the node before the given time.  The allow_equal flag indicates  whether instances at a time equal to t` are allowed. \n\nIf there is no such instance, returns nothing.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.output_type-Union{Tuple{Type{<:SFunc{I, O}}}, Tuple{O}, Tuple{I}} where {I, O}","page":"Core","title":"Scruff.output_type","text":"output_type(::Type{<:SFunc{I,O}}) where {I,O}\noutput_type(::SFunc{I,O}) where {I,O}\n\nReturn the output type (i.e. O) of the SFunc\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.output_type-Union{Tuple{Variable{I, J, O}}, Tuple{O}, Tuple{J}, Tuple{I}} where {I, J, O}","page":"Core","title":"Scruff.output_type","text":"output_type(::Variable{I,J,O})\noutput_type(::Placeholder{O})\n\nreturns the output type O of the given parameter\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.post_belief!-Tuple{Runtime, Instance, Any}","page":"Core","title":"Scruff.post_belief!","text":"post_belief!(runtime::Runtime, inst::Instance, belief)\n\nPosts the given evidence for the given instance.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.post_evidence!-Tuple{Runtime, Instance, Score}","page":"Core","title":"Scruff.post_evidence!","text":"post_evidence!(runtime::Runtime, inst::Instance, evidence)\n\nPosts the given evidence for the given instance.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.post_intervention!-Tuple{Runtime, Instance, SFunc{Tuple{}}}","page":"Core","title":"Scruff.post_intervention!","text":"post_intervention!(runtime::Runtime, inst::Instance, intervention::Dist)\n\nPosts the given intervention for the given instance.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.previous_instance-Tuple{DynamicRuntime, Node}","page":"Core","title":"Scruff.previous_instance","text":"previous_instance(runtime::DynamicRuntime, node::Node)\n\nReturns the previous instance for the given runtime and node.  This will throw and exception if there is no previous instance.\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.set_time!-Union{Tuple{T}, Tuple{DynamicRuntime{T}, T}} where T","page":"Core","title":"Scruff.set_time!","text":"set_time(runtime::Runtime{T}, newtime::T) -> T\n\nSets the current time for the given Runtime\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.set_value!-Tuple{Runtime, Instance, Symbol, Any}","page":"Core","title":"Scruff.set_value!","text":"set_value!(runtime::Runtime, instance::Instance, key::Symbol, value)\n\nSet the value on an instance for the given key\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.start_algorithm-Tuple{Function, Runtime, Vararg{Any}}","page":"Core","title":"Scruff.start_algorithm","text":"start_algorithm(alg_fun::Function, runtime::Runtime, args...)\n\nStarts the algorithm in the current thread\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.time_algorithm-Tuple{Function, Vararg{Any}}","page":"Core","title":"Scruff.time_algorithm","text":"time_algorithm(alg::Function, args...; fnamefilter=nothing, argfilter=nothing)\n\nWrap an algorithm (callect with its args) such that every Scruff function is called with the @timed macro.  The output is sent to the @info macro using Julia's logging system.  \n\nFiltering can be done on either the name of the method or the args list;  both parameters are functions that take a x::String or a x...,  respectively, as input and return true if the method is to be logged.\n\nThe output looks like a series of\n\n┌ Info: outgoing_pis\n│   time = \"0.0068000000000000005 ms\"\n│   bytes = 144\n└   gctime = 0.0\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.trace_algorithm-Tuple{Function, Vararg{Any}}","page":"Core","title":"Scruff.trace_algorithm","text":"trace_algorithm(alg::Function, args...; fnamefilter=nothing, argfilter=nothing)\n\nWrap an algorithm (called with its args) in a trace.  All Scruff functions and  their calling parameter values will be logged using the @info macro using  Julia's logging system.  \n\nFiltering can be done on either the name of the method or the args list;  both parameters are functions that take a x::String or a x..., respectively, as input and return true if the method is to be logged.\n\nThe output looks like a series of\n\n┌ Info: outgoing_pis\n│   called_by = operate at runtime.jl:387 [inlined]\n└   args = (DiscreteCPD{1}([[0.35, 0.65], [0.45, 0.55]]), [0.38, 0.6200000000000001], Any[]) \n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.trace_runtime-Tuple{Function, Vararg{Any}}","page":"Core","title":"Scruff.trace_runtime","text":"trace_runtime(alg::Function, args...; fnamefilter=nothing, argfilter=nothing)\n\nWrap Runtime methods (called with its args) in a trace.  All Scruff functions that have Runtime as a parameter and their calling parameter values will  be logged using the @info macro using Julia's logging system.  \n\nFiltering can be done on either the name of the method or the args list;  both parameters are functions that take a x::String or a x..., respectively, as input and return true if the method is to be logged.\n\nThe output looks like a series of\n\n┌ Info: get_variable\n│   called_by = get_definition at runtime.jl:93 [inlined]\n└   args = (Instance{Int64}(Variable{Int64,DiscreteCPD{1}}(:x5, DiscreteCPD{1}([[0.35, 0.65], [0.45, 0.55]])), 0),)\n\n\n\n\n\n","category":"method"},{"location":"lib/core/#Scruff.value_type-Union{Tuple{ValueTyped{O}}, Tuple{O}} where O","page":"Core","title":"Scruff.value_type","text":"value_type(v::ValueTyped{O}) where {O}\n\nreturn the actual type (i.e. O) of the ValueTyped\n\n\n\n\n\n","category":"method"},{"location":"tutorial/tutorial/#The-Scruff-Tutorial","page":"Tutorial","title":"The Scruff Tutorial","text":"","category":"section"},{"location":"tutorial/tutorial/#What-Scruff-is-all-about","page":"Tutorial","title":"What Scruff is all about","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Scruff is a flexible framework for building AI systems. Although its roots are in probabilistic programming, it is not strictly speaking a probabilistic programming language. Instead, it is a framework for combining models of different kinds and reasoning with them. Scruff provides three main features:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"The ability to combine different kinds of models and reason with them using an algorithm in an integrated way. Scruff decomposes the representation of models from algorithms that work with them using operators. Any representation (the scruff word is sfunc (stochastic function, pronounced \"essfunk\")) that implements the operators can appear in algorithms. Using this approach enables us to generalize algorithms like belief propagation and importance sampling that have traditionally been applied to probabilistic models. A given sfunc does not have to support all operators and algorithms can use sfuncs in the appropriate way. For example, it is legal to have an sfunc that you can't sample from, which would not be possible in a typical probabilistic programming language. \nA flexible framework for inference using these representations. Scruff distinguishes between the notion of a variable, which represents a value that can vary over time, and an instance of that variable, which represents its value at a particular time. In Scruff, variables are associated with models, which determine which sfunc to use for specific instances. There is no requirement that instances follow a regular time pattern; if the model supports it, instances can appear at any time interval. It is also possible to combine instances appearing at different time intervals, for example slowly changing and rapidly changing variables. Scruff also provides the ability to perform iterative inference, where beliefs about instances are refined through repeated computation.\nComposition, reuse, and experimentation with different models, sfuncs, and algorithms. Scruff comes with an extensible and structured library of models, sfuncs, operators, and algorithms, making it easy to mix and match or extend with your own. For example, it is possible to implement alternative versions of an operators for an sfunc side by side and choose between them manually, or even automatically based on the characteristics of the specific instance. Another example is to compare accuracy and runtime between different time granularities on a variable by variable basis. Finally, as sfunc composition is highly structured, it is possible to experiment with specific sfunc choices in a systematic way.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"The name Scruff derives from the old debates in AI between the neats and the scruffies. Neats believed that unless systems were developed in a coherent framework, it would be impossible to scale development of AI systems to complex real-world problems. Scruffies believed that real-world problems require a variety of techniques that must be combined as best as possible, and forcing everything into a neat framework would hinder progress. We believe that both camps have an element of the truth, and Scruff is an attempt to provide the best of both worlds. Scruff's philosophy is to allow a variety of representations and implementations to coexist side by side, and not every algorithm can be applied to every representation. However, they all coexist in a clean, well-defined and organized framework that enables scalable development of models and systems.","category":"page"},{"location":"tutorial/tutorial/#Some-opening-examples","page":"Tutorial","title":"Some opening examples","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"We start this tutorial with three examples illustrating idiomatic use of Scruff and some of its capabilities. These examples can be found in the docs/examples folder (they are also linked by the Examples page).","category":"page"},{"location":"tutorial/tutorial/#Instant-reasoning","page":"Tutorial","title":"Instant reasoning","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Our first example, found in novelty_example.jl is about detecting and characterizing novel behaviors. In this example, a behavior is simply something that generates a real number, but the example extends to more interesting kinds of behavior. The example shows how to create sfuncs, models, variables, and networks, and how to reason with them. We call this an instant reasoning example because there is no temporal element.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"We begin with some imports:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    using Scruff\n    using Scruff.Models\n    using Scruff.SFuncs\n    using Scruff.Algorithms","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Since we're going to run experiments with different setups, we define a NoveltySetup data structure.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    struct NoveltySetup\n        known_sfs::Vector{Dist{Float64}}\n        known_probs::Vector{Float64}\n        novelty_prob::Float64\n        novelty_prior_mean::Float64\n        novelty_prior_sd::Float64\n        novelty_sd::Float64\n    end","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Here, known_sfs is a vector of known behaviors, each one represented by a sfunc. In particular, each behavior is a Dist{Float64}, meaning it is an unconditional distribution over Float64. known_probs is the probabilities of the known behaviors, assuming the behavior is not novel, while novelty_prob is the probability that the behavior is novel. A novel behavior has a mean and standard deviation. The mean is drawn from a normal distrbution with mean novelty_prior_mean and standard deviation novelty_prior_sd. The novel behavior's own standard deviation is given by novelty_sd.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"We now define a function that takes a setup and returns a network. Since observations are also part of the network, this function also takes the number of observations as an argument.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    function novelty_network(setup::NoveltySetup, numobs::Int)::InstantNetwork","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"This function begins by defining some variables. For the first variable, we'll go through the steps in detail. For the remaining variables, we'll use some syntactic sugar. The first variable represents the known behavior. Defining it takes three steps: creating the sfunc, defining the model, and associating it with a variable. Much of Scruff's power comes from separating these three concepts. However, for the common case where we want to do all three of these things together, we provide syntactic sugar.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"First we create the sfunc:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    known_sf = Cat(setup.known_sfs, setup.known_probs)","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"This defines known_sf to be a categorical distribution, where the choices are provided by setup.known_sfs and the probabilities are specified by setup.known_probs. The important idea is that this distribution is an entity of its own, irrespective of specific variables that are related using it. An sfunc is similar to the mathematical concept of a function. It describes a relationship between variables that is not necessarily determinisitic. In mathematics, we can define concepts like function composition, which operate on the functions directly and don't require the notion of variables. Similarly in Scruff, there are a variety of ways to compose and combine sfuncs. Furthermore, we can have sfuncs be values in models as well, which enables higher-order probabilistic programming. In fact, in this example, known_sf represents a categorical distribution over sfuncs.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"After creating the sfunc, we create a model using the sfunc:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    known_model = SimpleModel(known_sf)","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"A model describes which sfunc to generate for a variable in different situations. In general, the sfunc representing a variable's distribution can change depending on the situation, such as the time of instantiation of the variable and times of related instances. Here, we just have a SimpleModel that always returns the same sfunc, but later we will have more interesting models.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"The third step is to create a variable and associate it with the model. This is achieved by calling the model with the variable name (a symbol) as argument:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    known = known_model(:known)","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"We now have the Julia variable known whose value is a Scruff variable with the name :known associated with known_model. If you just want to create a variable with a SimpleModel for a specific sfunc, you can use syntactic sugar as follows:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    known = Cat(setup.known_sfs, setup.known_probs)()(:known)","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"When we call the sfunc with zero arguments, we create a SimpleModel with the sfunc; then, when we apply that model to the variable name, we create the variable. In the rest of this example, we will use this form. Let's create some more variables:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    is_novel = Flip(setup.novelty_prob)()(:is_novel)\n    novelty_mean = Normal(setup.novelty_prior_mean, setup.novelty_prior_sd)()(:novelty_mean)\n    novelty = Det(Tuple{Float64}, Dist{Float64}, m -> Normal(m[1], setup.novelty_sd))()(:novelty)\n    behavior = If{Dist{Float64}}()()(:behavior)","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"is_novel represents whether the behavior is novel or known. This variable will be true with probability setup.novelty_prob. novelty_mean represents the mean of the novel behavior using a normal distribuiton whose mean and standard deviation are given by the setup. novelty uses an sfunc called Det, which stands for \"deterministic\". It describes a determinstic relationship between one or more arguments and a result. When you define a Det, you have to give the Julia compiler hints about the input and output types of the function. The input type of an sfunc in Scruff is always a tuple of arguments, so in this case it is a tuple of a single Float64 argument. Our intent is for this input to represent the mean of the novel behavior; however, as we have discussed, sfuncs exist independently of the variables to which they will be applied. The connection to the novelty mean will be made later. The output of the Det is an unconditional distribution of type Dist{Float64}. This is another example of an sfunc outputting an sfunc representing a behavior. We now have two such sfuncs: known and novelty. We are ready to choose the actual behavior, using the sf_choice variable. The sfunc for sf_choice is defined by If{Dist{Float64}}(). Unlike most probabilistic programming languages, which almost always provide an if control flow concept that choose between specific alternatives based on a test, Scruff's If describes the general process of choosing between two alternatives using a Boolean test. In this example, the intent is to choose between novelty and known based on is_novel. These connections will be made later. Note that the type of value produced by the If is a type parameter, which in this case is again a Dist{Float64}, representing the actual behavior that gets chosen.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Now that we have these variables, we are ready to start building the connections described in the previous paragraph. We will build the ingredients to an InstantNetwork, which are a list of variables, and a VariableGraph, representing a dictionary from variables to their parents.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    variables = [known, is_novel, novelty_mean, novelty, behavior]\n    graph = VariableGraph(novelty => [novelty_mean], behavior => [is_novel, novelty, known])","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Finally, we need to add observations, which is done in a flexible way depending on the number of observations.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    for i in 1:numobs\n        obs = Generate{Float64}()()(obsname(i))\n        push!(variables, obs)\n        graph[obs] = [behavior]\n    end","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"For each observation, we create a variable whose name is given by the utility function obsname(i). The sfunc is Generate{Float64}. Generate{Float64} is a second-order sfunc  that takes as input a Dist{Float64} and generates a Float64 from it.  Thus, each observation is an independent sample from the behavior.  We add the observation to the variables vector and make its parents the behavior variable.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Finally, we create the instant network and return it.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    return InstantNetwork(variables, graph)","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Now that we've built the network, we're ready to run some experiments.  Here's the code to run an experiment. It takes as arguments the setup, the vector of observations, and the InstantAlgorithm to use (an InstantAlgorithm is an algorithm run on an InstantNetwork; it does not handle dynamics).","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    function do_experiment(setup::NoveltySetup, obs::Vector{Float64}, alg::InstantAlgorithm)\n        net = novelty_network(setup, length(obs))\n        evidence = Dict{Symbol, Score}()\n        for (i,x) in enumerate(obs)\n            evidence[obsname(i)] = HardScore(x)\n        end\n        runtime = Runtime(net)\n        infer(alg, runtime, evidence)\n\n        is_novel = get_node(net, :is_novel)\n        novelty_mean = get_node(net, :novelty_mean)\n        println(\"Probability of novel = \", probability(alg, runtime, is_novel, true))\n        println(\"Posterior mean of novel behavior = \", mean(alg, runtime, novelty_mean))\n    end","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"do_experiment first creates the network and then builds up the evidence data structure, which is a dictionary from variable names to scores. In Scruff, a Score is an sfunc  with no outputs that specifies a number for each value of its input. A HardScore is a score that assigns the value 1 to its argument and 0 to everything else. The next step is to create a runtime using the network. The runtime holds all the information needed by the inference algorithm to perform its computations and answer queries. We then call infer, which does the actual work. Once infer completes, we can answer some queries. To answer a query, we need handles to the variables we want to use, which is done using the get_node method. Finally, the probability and mean methods give us the answers we want.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"The examples next defines some setups and an observation list.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    function setup(generation_sd::Float64, prob_novel::Float64)::NoveltySetup\n        known = [Normal(0.0, generation_sd), Normal(generation_sd, generation_sd)]\n        return NoveltySetup(known, [0.75, 0.25], prob_novel, 0.0, 10.0, generation_sd)\n    end\n    setup1 = setup(1.0, 0.1)\n    setup2 = setup(4.0, 0.1)\n    obs = [5.0, 6.0, 7.0, 8.0, 9.0]","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"In setup1, behaviors have a smaller standard deviation, while in setup2,  the standard deviation is larger. We would expect the posterior probability of is_novel to be higher for setup1 than setup2 because it is harder to explain the observations with known behaviors when they have a small standard deviation.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Finally, we run some experiments. ","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    println(\"Importance sampling\")\n    println(\"Narrow generation standard deviation\")\n    do_experiment(setup1, obs, LW(1000))\n    println(\"Broad generation evidence\")\n    do_experiment(setup2, obs, LW(1000))\n\n    println(\"\\nBelief propagation\")\n    println(\"Narrow generation standard deviation\")\n    do_experiment(setup1, obs, ThreePassBP())\n    println(\"Broad generation evidence\")\n    do_experiment(setup2, obs, ThreePassBP())\n\n    println(\"\\nBelief propagation with larger ranges\")\n    println(\"Narrow generation standard deviation\")\n    do_experiment(setup1, obs, ThreePassBP(25))\n    println(\"Broad generation evidence\")\n    do_experiment(setup2, obs, ThreePassBP(25))","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"LW(1000) creates a likelihood weighting algorithm that uses 1000 particles, while ThreePassBP() creates a non-loopy belief propagation  algorithm. In this example, the network has no loops so using a non-loopy BP algorithm is good. However, BP needs to discretize the continuous variables, which most of the variables in this example are. With no arguments, it uses the default number of bins (currently 10). ThreePassBP(25) creates a BP algorithm that uses 25 bins. ","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"The first time you run this example, it might take a while. Julia uses just in time (JIT) compilation, so the first run can involve a lot of compilation overhead. But subsequent runs are very fast. When you run this example, it produces output like this:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"julia> include(\"docs/examples/novelty_example.jl\")\nImportance sampling\nNarrow generation standard deviation\nProbability of novel = 1.0\nPosterior mean of novel behavior = 7.334211013744095\nBroad generation evidence\nProbability of novel = 0.1988404327033635\nPosterior mean of novel behavior = 0.631562661691411\n\nBelief propagation\nNarrow generation standard deviation\nProbability of novel = 1.0\nPosterior mean of novel behavior = 7.71606183538526\nBroad generation evidence\nProbability of novel = 0.2534439250343668\nPosterior mean of novel behavior = 1.7131189737655137\n\nBelief propagation with larger ranges\nNarrow generation standard deviation\nProbability of novel = 1.0\nPosterior mean of novel behavior = 6.979068103646596\nBroad generation evidence\nProbability of novel = 0.2591460898562207\nPosterior mean of novel behavior = 1.7363865329521413","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"We see that as expected, the probability of novel is much higher with narrow generation standard deviation than with broad. All three algorithms have similar qualitative results. Running the experiment a few times shows that the importance sampling method has relatively high variance. We also see that the estimate of the posterior mean changes significantly as we add more values to the ranges of variables for the BP method.","category":"page"},{"location":"tutorial/tutorial/#Incremental-reasoning","page":"Tutorial","title":"Incremental reasoning","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Building on the last point, our next example, found in  novelty_lazy.jl, uses Scruff's  incremental inference capabilities to gradually increase the range sizes of the  variables to improve the estimates. We're going to use an algorithm called Lazy Structured Factored Inference (LSFI). LSFI repeatedly calls an InstantAlgorithm (in this case variable elimination) on more and more refined versions of the network. Refinement generally takes two forms: Expanding recursive networks to a greater depth,  and enlarging the ranges of continuous variables. Our example only has the latter refinement. When expanding recursive networks, LSFI can produce lower and upper bounds to query answers at each iteration. This capability is less useful for range refinement, but our code needs to handle the bounds.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"The network and setups are just as in novelty_example.jl. The code for running an experiment is similar in structure but has some new features.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    function do_experiment(setup, obs)\n        net = novelty_network(setup, length(obs))\n        is_novel = get_node(net, :is_novel)\n        novelty_mean = get_node(net, :novelty_mean)\n        evidence = Dict{Symbol, Score}()\n        for (i,x) in enumerate(obs)\n            evidence[obsname(i)] = HardScore(x)\n        end\n\n        alg = LSFI([is_novel, novelty_mean]; start_size = 5, increment = 5)\n        runtime = Runtime(net)\n        prepare(alg, runtime, evidence)\n\n        for i = 1:10\n            println(\"Range size: \", alg.state.next_size)\n            refine(alg, runtime)\n            is_novel_lb = probability_bounds(alg, runtime, is_novel, [false, true])[1]\n            println(\"Probability of novel = \", is_novel_lb[2])\n            println(\"Posterior mean of novel behavior = \", mean(alg, runtime, novelty_mean))\n        end\n    end","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"As before, the code creates the network, gets handles of some variables, and fills the evidence data structure. In this case, we use LSFI. When creating an LSFI algorithm, we need to tell it which variables we want to query, which are is_novel and novelty_mean. LSFI also has some optional arguments. In this example, we configure it to have a starting range size of 5 and increment the range size by 5 on each refinement. Before running inference, we need to call prepare(alg, runtime, evidence). Then we go through ten steps of refinement. We can get the range size of the next refinement using alg.state.next_size (we only use this for printing).  Refinement is done through a call to refine(alg, runtime). We then need to do a little more work than before to get the answers to queries because of the probabilities bounds. probability_bounds(alg, runtime, is_novel, [false, true]) returns lower and upper bounds  as 2-element vectors of probabilities of false and true. As discussed earlier, these bounds are not true bounds in the case of range refinement, so we just pick the first one, and then pick the second value, corresponding to true, out of that vector. The mean method already arbitrarily uses the lower bounds so we don't have to do any work there.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Running this example produces a result like:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Lazy Inference\nNarrow generation standard deviation\nRange size: 5\nProbability of novel = 1.0\nPosterior mean of novel behavior = 5.0\nRange size: 10\nProbability of novel = 1.0\nPosterior mean of novel behavior = 5.000012747722526\nRange size: 15\nProbability of novel = 1.0\nPosterior mean of novel behavior = 5.000012747722526\nRange size: 20\nProbability of novel = 1.0\nPosterior mean of novel behavior = 5.000012747722526\nRange size: 25\nProbability of novel = 1.0\nPosterior mean of novel behavior = 5.000012747722526\nRange size: 30\nProbability of novel = 1.0\nPosterior mean of novel behavior = 5.000012747722526\nRange size: 35\nProbability of novel = 1.0\nPosterior mean of novel behavior = 5.000012747722526\nRange size: 40\nProbability of novel = 1.0\nPosterior mean of novel behavior = 5.000012747722526\nRange size: 45\nProbability of novel = 1.0\nPosterior mean of novel behavior = 5.000012747722526\nRange size: 50\nProbability of novel = 1.0\nPosterior mean of novel behavior = 5.000012747722526\n\nBroad generation evidence\nRange size: 5\nProbability of novel = 0.23525574698998955\nPosterior mean of novel behavior = 1.1750941076530532\nRange size: 10\nProbability of novel = 0.19825748797545847\nPosterior mean of novel behavior = -0.11214142944113853\nRange size: 15\nProbability of novel = 0.19745646974840933\nPosterior mean of novel behavior = -0.11168834527313051\nRange size: 20\nProbability of novel = 0.19283490006948978\nPosterior mean of novel behavior = 0.3602757973718763\nRange size: 25\nProbability of novel = 0.1926826680899825\nPosterior mean of novel behavior = 0.35995765581210176\nRange size: 30\nProbability of novel = 0.1825284089501074\nPosterior mean of novel behavior = 1.1318032244818\nRange size: 35\nProbability of novel = 0.18251757269528399\nPosterior mean of novel behavior = 1.1294239567980586\nRange size: 40\nProbability of novel = 0.18251757269528404\nPosterior mean of novel behavior = 1.1294239567980597\nRange size: 45\nProbability of novel = 0.18251757269528404\nPosterior mean of novel behavior = 1.1294239567980597\nRange size: 50\nProbability of novel = 0.18251757269528404\nPosterior mean of novel behavior = 1.1294239567980597","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Looking at this output, we see that the narrow generation standard deviation case is easy and the algorithm  quickly converges. However, in the broad generation standard deviation case, we see that there is a big change in the posterior mean of novel behavior between range size 25 and 30. This is to do with the way values in the range are generated. As the range size is increased, values further and further away from the prior mean are created. At range size 30, a value is introduced that has low prior but fits the data well, which increases the posterior mean.","category":"page"},{"location":"tutorial/tutorial/#Dynamic-reasoning","page":"Tutorial","title":"Dynamic reasoning","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Our final example novelty_filtering.jl riffs on the novelty theme to use dynamic reasoning. Now, observations are received over time at irregular intervals. A behavior now represents the velocity of an object moving in one dimension, starting at point 0.0. This example moves away from the higher-order sfuncs but introduces some new kinds of models.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"The setup is similar but slightly different:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    struct NoveltySetup\n        known_velocities::Vector{Float64}\n        known_probs::Vector{Float64}\n        novelty_prob::Float64\n        novelty_prior_mean::Float64\n        novelty_prior_sd::Float64\n        transition_sd::Float64\n        observation_sd::Float64\n    end","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"We have known velocities and their probabilities, the probability of novelty, and the mean and standard deviation of the novel velocity. We also have the standard deviation of the transition and observation models.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Because the observations appear irregularly and not at fixed time steps, we are going to use a VariableTimeModel to represent the position of the object.  To create a VariableTimeModel, we need to create a new type that inherits from  VariableTimeModel and implement the methods make_initial, which creates the sfunc for the initial time step, and make_transition, which creates the sfunc at each time step at which we instantiate the variable. ","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    struct PositionModel <: VariableTimeModel{Tuple{}, Tuple{Float64, Float64}, Float64} \n        setup::NoveltySetup\n    end\n    function make_initial(::PositionModel, ::Float64)::Dist{Float64}\n        return Constant(0.0)\n    end\n    function make_transition(posmod::PositionModel, parenttimes::Tuple{Float64, Float64}, time::Float64)::SFunc{Tuple{Float64, Float64}, Float64}\n        function f(pair)  \n            (prevval, velocity) = pair\n            Normal(prevval + t * velocity, t * posmod.setup.transition_sd)\n        end\n        t = time - parenttimes[1]\n        return Chain(Tuple{Float64, Float64}, Float64, f)\n    end","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"make_initial simply returns Constant(0.0), meaning that the object always starts at position 0.0 with no uncertainty. Because the amount of time between instantiations is variable, make_transition takes as argument a vector of times of the previous instantiation of its parents, as well as the current time.  It uses these times to determine exactly what the transition model should be. Here, it computes the time t between the current time and the previous instantiation of the first parent, which we will later connect to the position variable. So t represents the time since the last instantiation of the position variable. make_transition uses the Chain sfunc, which takes parent values and applies  a Julia function to produce the sfunc used to generate the value of the Chain. In this case, once we make the connections, the Chain will take the previous value of  the position and the velocity and create a Normal sfunc whose mean and standard deviation depend on t, as well as the standard deviation of the transition model in the setup. This Normal is then used to generate the current position. This code is a little sophisticated, but the ability to create variable time models and perform  asynchronous dynamic reasoning is a powerful feature of Scruff.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"The rest of the example is simpler and we won't go over it in full detail. We do introduce the StaticModel, which represents a variable whose value is generated at the beginning of a run and never changes.  StaticModel is implemented as a VariableTimeModel where the transition function is  the identify function. Also, the observation variable uses a SimpleModel, because it is generated afresh  instantaneously every time it is instantiated. It is defined to be a normal whose mean is the position and whose standard deviation is given by the setup. This is implemented using the LinearGaussian sfunc.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"A DynamicNetwork uses two variable graphs for the initial and transition steps. In this example, all the logic of choosing the behavior happens in the initial graph, while the position logic and its dependence on previous position and velocity is in the transition graph. The transition graph also contains copy edges for the static variables.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    variables = [known_velocity, is_novel, novel_velocity, velocity, position, observation]\n    initial_graph = VariableGraph(velocity => [is_novel, novel_velocity, known_velocity], observation => [position])\n    transition_graph = VariableGraph(known_velocity => [known_velocity], is_novel => [is_novel], novel_velocity => [novel_velocity], velocity => [velocity], position => [position, velocity], observation => [position])","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"We'll show the do_experiment implementation in detail because it illustrates how  asynchronous inference is performed.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    function do_experiment(setup::NoveltySetup, obs::Vector{Tuple{Float64, Float64}}, alg::Filter)\n        net = novelty_network(setup, length(obs))\n        runtime = Runtime(net, 0.0) # Set the time type to Float64 and initial time to 0\n        init_filter(alg, runtime)\n\n        is_novel = get_node(net, :is_novel)\n        velocity = get_node(net, :velocity)\n        observation = get_node(net, :observation)\n\n        for (time, x) in obs\n            evidence = Dict{Symbol, Score}(:observation => HardScore(x))\n            println(\"Observing \", x, \" at time \", time)\n            # At a minimum, we need to include query and evidence variables in the filter step\n            filter_step(alg, runtime, Variable[is_novel, velocity, observation], time, evidence)\n\n            println(\"Probability of novel = \", probability(alg, runtime, is_novel, true))\n            println(\"Posterior mean of velocity = \", mean(alg, runtime, velocity))\n        end\n    end","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"After creating the network, we create a runtime. The call to Runtime takes a second argument that not only sets the initial time but also established the type used to represent time, which is Float64. We first need to initialize the filter with init_filter which runs the initial time step, and get handles  to the variables we care about. Our observation sequence is a vector (sorted by increasing time) of (time, value) pairs. For each such pair, we create the evidence at that time point. Then we run a filter_step. Besides the algorithm and runtime, the filter step takes a vector of variables to instantiate, the current time, and the evidence. There is no need to instantiate all the variables at every filter step. At a minimum, we need to instantiate evidence variables as well as any variables we want to query. Since we're going to query is_novel and velocity, we'll have to instantiate those using their copy transition model. However, we never need to instantiate the known_velocity and novel_velocity variables after the initial time step. Finally, we can answer queries about the current state in a similar way to the other examples.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"For the experiments, we create a setup and two sequences of observations, the second of which is harder to explain with known behaviors.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"    # Known velocities are 0 and 1, novelty has mean 0 and standard deviation 10\n    setup = NoveltySetup([0.0, 1.0], [0.7, 0.3], 0.1, 0.0, 10.0, 1.0, 1.0)\n    obs1 = [(1.0, 2.1), (3.0, 5.8), (3.5, 7.5)] # consistent with velocity 2\n    obs2 = [(1.0, 4.9), (3.0, 17.8), (3.5, 20.5)] # consistent with velocity 6","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"We then use CoherentPF(1000) as the filtering algorithm. Current filtering algorithms in  Scruff combine an instantiation method that creates a window with an underlying  InstantAlgorithm to infer with the window. Available window creation methods include synchronous, asynchronous, and coherent. Coherent is similar to asynchronous except that it adds variables to the instantiation to maintain coherence of parent-child relationships. In this example, it ensures that the position variable is also instantiated, not just the query and evidence variables. CoherentPF(1000) describes a particle filter that uses a coherent window creator and an importance sampling algorithm with 1000 particles. The example also shows how you can similarly create a coherent BP algorithm. However, BP does not work well in models with static variables because dependencies between the static variables are lost between filtering steps.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Running this example produces output like the following for the particle filter:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Particle filter\nSmaller velocity\nObserving 2.1 at time 1.0\nProbability of novel = 0.0351642575352557\nPosterior mean of velocity = 0.5411884423148781\nObserving 5.8 at time 3.0\nProbability of novel = 0.057222570825582145\nPosterior mean of velocity = 0.8705507592898075\nObserving 7.5 at time 3.5\nProbability of novel = 0.08166159149240186\nPosterior mean of velocity = 1.007810909419299\n\nLarger velocity\nObserving 4.9 at time 1.0\nProbability of novel = 0.6741688102988623\nPosterior mean of velocity = 3.6150131656907174\nObserving 17.8 at time 3.0\nProbability of novel = 1.0\nPosterior mean of velocity = 5.898986723263269\nObserving 20.5 at time 3.5\nProbability of novel = 1.0\nPosterior mean of velocity = 5.86994402484129","category":"page"},{"location":"tutorial/tutorial/#Scruff-concepts","page":"Tutorial","title":"Scruff concepts","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"The central concepts of Scruff are:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Sfuncs, or stochastic functions, which represent mathematical relationships between variables\nOperators, which define and implement computations on sfuncs\nModels, which specify how to create sfuncs in different situations\nVariables, which represent domain entities that may take on different values at different times\nNetworks, which consist of variables and the dependencies between them\nInstances, which represent a specific instantiation of a variable at a point in time\nAlgorithms, which use operations to perform computations on networks\nRuntimes, which manage instances as well as information used by algorithms","category":"page"},{"location":"tutorial/tutorial/#Sfuncs","page":"Tutorial","title":"Sfuncs","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"An SFunc has an input type, which is a tuple, and an output type. Although the name implies probabilistic relationships, in principle sfuncs can be used to represent any kind of information. The representation of an sfunc is often quite minimal, with most of the detail contained in operators. The general type is SFunc{I <: Tuple, O}.","category":"page"},{"location":"tutorial/tutorial/#Dists","page":"Tutorial","title":"Dists","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"A Dist{O} is an SFunc{Tuple{}, O}. In other words, a Dist represents an unconditional distribution with no parents. Examples of Dist include Constant, Cat, Flip, and Normal.","category":"page"},{"location":"tutorial/tutorial/#Scores","page":"Tutorial","title":"Scores","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"A Score{I} is an SFunc{Tuple{I}, Nothing}. In other words, it takes a single value of  type I, and rather than produce an output, it just associates information (typically a likelihood) with its input. A Score is often used to represent evidence. Examples of Score include HardScore (only a single value allowed),  SoftScore (allows multiple values), LogScore (similar to SoftScore but represented in log form), FunctionalScore (score is computed by applying a function to the input), NormalScore (representing a normal distribution around a value),  and Parzen (mixture of normal scores).","category":"page"},{"location":"tutorial/tutorial/#Conditional-Sfuncs","page":"Tutorial","title":"Conditional Sfuncs","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Scruff provides a range of ways to construct sfuncs representing conditional distributions. These are organized in a type hierarchy:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"— Invertible: deterministic functions with a deterministic inverse, enabling efficient operator implementations\n— Det: deterministic functions without an inverse\n   └ Switch: chooses between multiple incoming choices based on first argument\n      └ LinearSwitch: first argument is an integer and switch chooses corresponding result\n      └ If: first argument is a Boolean and switch chooses appropriate other argument \n— Conditional: abstract representation of sfuncs that use first arguments to create sfunc to apply to other arguments\n   └ LinearGaussian: sfunc representing normal distribution whose mean is a linear function of the parents\n   └ Table: abstract representation of sfuncs that use first arguments to choose sfunc to apply from a table\n      └ DiscreteCPT: discrete conditional probability table\n      └ CLG: conditional linear Gaussian model: table of linear Gaussians depending on discrete parents\n— Separable: Mixture of DiscreteCPT to decompose dependency on many parents, enabling efficient operator implementations\n","category":"page"},{"location":"tutorial/tutorial/#Compound-Sfuncs","page":"Tutorial","title":"Compound Sfuncs","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Compound sfuncs can be though of as a construction kit to compose more complex sfuncs out of simpler ones. These also include some higher-order sfuncs.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Generate: generate a value from its sfunc argument\nApply: similar to generate, but the sfunc argument is applied to another argument\nChain: apply a function to the arguments to produce an sfunc, then generate a value from the sfunc\nMixture: choose which sfunc to use to generate values according to a probability distribution\nSerial: connect any number of sfuncs in series\nNetworkSFunc: connect any number of sfuncs according to a graph\nExpander: apply a function to the arguments to produce a network that can be used recursively","category":"page"},{"location":"tutorial/tutorial/#Operators","page":"Tutorial","title":"Operators","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"An operator represents a computation that can be performed on an sfunc. An operator is not just a function or a method.  It is an object that can contain information (such as configuration instructions) and can be reasoned about, for example to specify policies to choose between alternative implementations. Operators consist of definitions, created using @op_def, which specify type information, and implementation, created using @impl.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Here are some of the most commonly used operators:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"cpdf(sf, parent_values, x) returns the conditional probability of x given parent_values\nlogcpdf(sf, parent_values, x)\nsample(sf, parent_values)\nget_score(sf, x) returns the score associated with x\nget_log_score(sf, x)\nsupport(sf, parent_ranges, target_size, current) computes a range of values for the sfunc given that the parents have values in parent_ranges. target_size is guidance as to the size of support to produce, which does not need to be obeyed precisely. current is a list of values that should be included in the support, which is useful for iterative refinement.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"The above operators will be implemented specifically for a given sfunc. In general, an sfunc does not need to support all operators. For example, typically only a Score will support get_score and get_log_score.  Some sfuncs will not be able to support sampling or density computation, and that's okay. For example, if an sfunc doesn't support sample, but it does support cpdf, and that sfunc is always observed, it can be used in likelihood weighting. If it is not always observed, it won't be usable in importance sampling but it might be usable in BP. The goal is to enable representations to be used as much as possible, rather than require everything to work uniformly. This is where the scruffiness of Scruff comes in.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"There are a variety of operators useful in BP and related algorithms. Most of these have default implementations that work for sfuncs in general and you don't need to worry about implementing them for a new sfunc.  The two that need to be implemented specifically are:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"compute_pi(sf, range, parent_ranges, parent_pi_messages), which integrates over the parents to produce a distribution over the value of the instance associated with the sfunc. The parent_pi_messages, as well as the computed distribution, are represented as Dists, rather than vectors or anything specific, which enables great flexibility in implementation.\nsend_lambda(sf, lambda, range, parent_ranges, parent_pi_messages, parent_index) computes the lambda message to be sent to the parent specified by parent_index.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Once these two operators are implemented for an sfunc, the sfunc can participate in any BP algorithm. Furthermore, sfuncs at the leaves of a network do not need to implement compute_pi. For example, send_lambda can be implemented for a feedforward neural network, enabling it to be included in a general BP inference process.","category":"page"},{"location":"tutorial/tutorial/#Models","page":"Tutorial","title":"Models","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"One of Scruff's key features is the ability to reason flexibly about variables that vary over time, and, in future, space. This is accomplished using models, which specify how to make the sfunc to use for a particular instance of a variable. Currently, Scruff's models library is relatively small. We plan to expand it in future, for example with learning models that improve their sfuncs based on experience.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Here is the current type hierarchy of models","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"—InstantModel: for a variable with no dependencies on previous time points\n  └ TimelessInstantModel: an InstantModel where the sfunc also does not depend on the current time\n  └ SimpleModel: a TimelessInstantModel in which the sfunc to use is passed in the definition of the model\n— FixedTimeModel: a model for a variable that depends on its own state at the previous time point and other variables at the current time point. The delta between the current and previous time point must be a fixed dt.\n  └ TimelessFixedTimeModel: a FixedTimeModel in which the sfunc does not depend on the current time\n  └ HomogenousModel: a TimelessFixedTimeModel in which the initial and transition sfuncs are passed in the definition of the model\n— VariableTimeModel: a model for a variable whose transition sfunc depends on the time intervals since the instantiations of its parents (which may be at different times)\n  └ StaticModel: a model for a variable whose value is set in the initial time point and never changes afterward\n","category":"page"},{"location":"tutorial/tutorial/#Networks","page":"Tutorial","title":"Networks","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Networks contains nodes, which are either variables or placeholders. Unlike variables, placeholders are not associated with models. Rather, they are intended to indicate values that should be received from outside the network. They are particularly useful for recursive reasoning, as well as dynamic inference.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"An InstantNetwork is created with two to four arguments:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"A vector of variables\nA variable graph, associating variables with their parents. If a variable has no parents, it can be omitted from the graph.\n(Optional) A vector of placeholders, which defaults to empty\n(Optional) A vector of outputs, which should be a subset of the variables, again defaults to empty. This is intended to support providing an interface to networks that enables internal nodes and embedded networks to be eliminated, but this feature is not used yet.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"A DynamicNetwork is created with three to six arguments","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"A vector of variables\nAn initial variable graph\nA transition variable graph\n(Optional) A vector of initial placeholders, defaults to empty\n(Optional) A vector of transition placeholders, defaults to empty\n(Optional) A vector of outputs, defaults to empty","category":"page"},{"location":"tutorial/tutorial/#Algorithms","page":"Tutorial","title":"Algorithms","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Scruff's algorithms library is structured so that more complex algorithms can be built out of simpler algorithms. The basic algorithms are instances of InstantAlgorithm and run on an InstantNetwork. Scruff currently provides the following hierarchy of instant algorithms. We intend to expand this list over time:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"— InstantAlgorithm: abstract type for which implementations must implement the infer method\n  └ Importance: general importance sampling framework\n    └ Rejection: rejection sampling\n    └ LW: likelihood weighting\n    └ Custom proposal: An importance sampling algorithm can be made from a proposal scheme using make_custom_proposal. A proposal scheme specifies alternative sfuncs to use as alternatives to the prior distribution for specific sfuncs\n  └ BP: general belief propagation framework\n    └ ThreePassBP: non-loopy belief propagation\n    └ LoopyBP\n  └ VE: variable elimination","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Scruff provides iterative algorithms that gradually improve their answers over time. These follow the following hierarchy:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"— IterativeAlgorithm: abstract type for which implementations must implement the prepare and refine methods\n  └ IterativeSampler: iterative algorithm that uses a sampler to increase the number of samples each refinement. For example, you can use IterativeSampler(LW(1000)) to use a likelihood weighting algorithm that adds 1,000 more samples on each call to refine.\n  └ LazyInference: an algorithm that expands the recursion depth and ranges of variables on each call to refine and then invokes an InstantAlgorithm\n    └ LSFI: a LazyInference algorithm that uses variable elimination as its instant algorithm","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"For filtering, Scruff provides the general Filter class, for which implementations must implement the init_filter and filter_step methods. All current filter implementations in Scruff derive from WindowFilter, where, on each call to filter_step, the algorithm first creates an InstantNetwork representing a window and then invokes an InstantAlgorithm. To create a WindowFilter, you choose a windowing method from SyncWindow, AsyncWindow, and CoherentWindow, and specify the instant algorithm to use. For example, Scruff provides the following constructor for asynchronous BP:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"AsyncBP(range_size = 10, T = Float64) = WindowFilter(AsyncWindow{T}(), ThreePassBP(range_size))","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Once algorithms have been run, queries can be answered using a uniform interface. This includes methods like marginal, joint, probability (which could be the probability of a specific value or the probability of a predicate), expectation, mean, and variance. As usual, not all algorithms need implement all queries.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"When you implement a new algorithm, you can specify how to answer queries using a standard answer method. Take a look at algorithm implementations to see how this works.","category":"page"},{"location":"tutorial/tutorial/#The-runtime","page":"Tutorial","title":"The runtime","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Unless you are implementing a new algorithm, you can largely ignore details of the runtime after you have created it, as everything happens under the hood. In general, the responsibilities of the runtime are to:","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Instantiate variables and associate them with the correct instance parents and sfunc\nIdentify the appropriate instances of variables at different point in time\nStore and retrieve values associated with instances\nStore and retrieve algorithm state across multiple invocations (e.g., using refine)\nManage passing of messages between variables","category":"page"},{"location":"tutorial/tutorial/#Future-work","page":"Tutorial","title":"Future work","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Future work in Scruff will follow five main lines:  developing more extensive libraries, including integration of other frameworks; developing a larger suite of algorithms using compositional methods; developing a more flexible framework of networks and recursive models;  creating spatial and spatiotemporal models with the same flexibility as current temporal models; and operators for performance characterization and optimization. We welcome contributions from the user community. If any of these items catches your interest, let us know and we will be happy to help with design and development.","category":"page"},{"location":"tutorial/tutorial/#Larger-libraries-and-integration-of-other-frameworks","page":"Tutorial","title":"Larger libraries and integration of other frameworks","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Scruff's current library, particularly of SFuncs, is fairly minimal, and needs to be extended to provide a fully functional probabilistic programming framework. Our intent is not to write sfuncs ourselves, but rather to wrap existing implementations wherever possible. An immediate goal is to wrap Distributions.jl, while will provide a wide range of Dist sfuncs. We also want to integrate with other probabilistic programming frameworks in Julia, such as Gen.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"In addition, the ability to use data-driven models that don't support sampling but do support inference is central to Scruff. We want to develop a library of such models, again by integrating with existing frameworks and wrapping with appropriate observations. Algorithms also need to be modified to take advantage of such models.","category":"page"},{"location":"tutorial/tutorial/#More-algorithms","page":"Tutorial","title":"More algorithms","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"It is important that algorithms in Scruff are well-structured and compositional. The algorithms developed so far are a starter set that have been carefully designed with this philosophy. Noticable by its absence is MCMC, which is common in many probabilistic programming frameworks. Gibbs sampling can be implemented as a message passing algorithm and fits well with the current framework. Metropolis-Hastings and reversible jump algorithms will take more thought, but experience with other  probabilistic programming languages should show how to implement them in a consistent, compositional way.","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"A very natural next step is to generalize our algorithms to use other semirings besides aum-product. Again, this should happen in a compositional way. It should be possible to say something like with_semiring(semiring, algorithm) and have all computations in operators invoked by the algorithm drawn from the appropriate semiring. If we do this, it will be natural to write learning algorithms like EM and decision-making algorithms using maximum  expected utility using our instant algorithms. This will lead to powerful combinations. Would anyone like asynchronous online EM using BP?","category":"page"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Similarly, BP is just one example of a variational method. We want to expand BP into a more general compositional variational inference library. Finally, we want to generalize our elimination methods to employ conditioning as well as elimination.","category":"page"},{"location":"tutorial/tutorial/#More-flexible-networks-and-recursion","page":"Tutorial","title":"More flexible networks and recursion","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"The ability for networks to contain other networks is critical to structured, modular, representations as well as efficient inference through encapsulation and conditional compilation. In addition, the ability to generate contained networks stochastically supports open universe modeling.  Scruff currently supports these capabilities through Expanders. However, Expanders were an early addition to Scruff and are not integrated all that well in the most recent Scruff development. NetworkSFuncs are better integrated, but do not currently support containment and recursion. We want to align Expanders and NetworkSFuncs to provide more general structured and recursive networks.","category":"page"},{"location":"tutorial/tutorial/#Spatially-flexible-models","page":"Tutorial","title":"Spatially flexible models","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Scruff currently has a flexible representation of variables that vary over time, but not of variables that vary over space, or space and time together. We want to provide spatiotemporal networks with the same flexibility as current DynamicNetworks. Moving beyond spatial models, we also want to create a framework for reasoning about variables that vary across graphs, such as social networks.","category":"page"},{"location":"tutorial/tutorial/#Performance-Characterization-and-Optimization","page":"Tutorial","title":"Performance Characterization and Optimization","text":"","category":"section"},{"location":"tutorial/tutorial/","page":"Tutorial","title":"Tutorial","text":"Scruff's design is intended to enable reasoning about performance characteristics of operators and to support algorithms making decisions about which operators to use. Multiple operator implementations can exist side by side for given sfuncs and algorithms can use policies to decide which ones to use. This capability is currently only exercised in very rudimentary ways. We want to take advantage of this capability to provide a wide set of performance characteristics and intelligent algorithms that use them.","category":"page"},{"location":"tutorial/examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"tutorial/examples/","page":"Examples","title":"Examples","text":"rembrandt_example.jl\nnovelty_example.jl\nnovelty_lazy.jl\nnovelty_filtering.jl\nsoccer_example.jl","category":"page"},{"location":"lib/rtutils/#scruff_rtutils","page":"Runtime Utilities","title":"Scruff.RTUtils","text":"","category":"section"},{"location":"lib/rtutils/","page":"Runtime Utilities","title":"Runtime Utilities","text":"    Modules = [Scruff.RTUtils]","category":"page"},{"location":"lib/rtutils/#Scruff.RTUtils.RANGE","page":"Runtime Utilities","title":"Scruff.RTUtils.RANGE","text":"RANGE\n\nThe constant key used to store the range of a specific variable instance \n\n\n\n\n\n","category":"constant"},{"location":"lib/rtutils/#Scruff.RTUtils.default_initializer","page":"Runtime Utilities","title":"Scruff.RTUtils.default_initializer","text":"Deprecated\n\n\n\n\n\n","category":"function"},{"location":"lib/rtutils/#Scruff.RTUtils.expander_range-Tuple{Runtime, Variable, Int64, Int64}","page":"Runtime Utilities","title":"Scruff.RTUtils.expander_range","text":"function expander_range(runtime :: Runtime, v :: Variable,\n    target_size :: Int, depth :: Int)\n\nRecursively compute the range of the expander and subnetworks up to the given depth.\n\nComputing the range of the expander expands enough of the parent           range to reach the desired target size, or expands all the parents fully.\n\n\n\n\n\n","category":"method"},{"location":"lib/rtutils/#Scruff.RTUtils.get_range","page":"Runtime Utilities","title":"Scruff.RTUtils.get_range","text":"get_range(runtime::Runtime, inst::Instance, depth = max_value(Int))\n\nReturns the range value for the given instance; this will return nothing if no range has been set.\n\nThe depth specifies the maximum depth of range desired.\n\n\n\n\n\n","category":"function"},{"location":"lib/rtutils/#Scruff.RTUtils.get_range-Union{Tuple{O}, Tuple{InstantRuntime, Node{O}}, Tuple{InstantRuntime, Node{O}, Any}} where O","page":"Runtime Utilities","title":"Scruff.RTUtils.get_range","text":"get_range(runtime::InstantRuntime, v::Node{O}, depth = 1) where O\n\nReturns the range of the given node.\n\n\n\n\n\n","category":"method"},{"location":"lib/rtutils/#Scruff.RTUtils.get_range-Union{Tuple{O}, Tuple{J}, Tuple{I}, Tuple{DynamicRuntime, Variable{I, J, O}}, Tuple{DynamicRuntime, Variable{I, J, O}, Any}} where {I, J, O}","page":"Runtime Utilities","title":"Scruff.RTUtils.get_range","text":"get_range(runtime::DynamicRuntime, v::Variable{I,J,O}, depth = 1) where {I,J,O}\n\nReturns the range of the most recent instance of the given variable.\n\n\n\n\n\n","category":"method"},{"location":"lib/rtutils/#Scruff.RTUtils.parent_ranges-Union{Tuple{O}, Tuple{J}, Tuple{I}, Tuple{Runtime, Variable{I, J, O}}, Tuple{Runtime, Variable{I, J, O}, Any}} where {I, J, O}","page":"Runtime Utilities","title":"Scruff.RTUtils.parent_ranges","text":"parent_ranges(runtime::Runtime, var::Variable{I,J,O}, depth = typemax(Int)) where {I,J,O}\n\nReturns the ranges of the parents of the given variable.\n\nSee Scruff.get_range\n\n\n\n\n\n","category":"method"},{"location":"lib/rtutils/#Scruff.RTUtils.set_range!-Union{Tuple{O}, Tuple{Runtime, Instance{O}, Vector{<:O}}, Tuple{Runtime, Instance{O}, Vector{<:O}, Int64}} where O","page":"Runtime Utilities","title":"Scruff.RTUtils.set_range!","text":"set_range!(runtime::Runtime, inst::Instance{O}, range::Vector{<:O}, depth::Int = 1) where O\n\nSets the range value for the given instance. Defaults to depth of 1.\n\n\n\n\n\n","category":"method"},{"location":"lib/rtutils/#Scruff.RTUtils.set_ranges!","page":"Runtime Utilities","title":"Scruff.RTUtils.set_ranges!","text":"set_ranges!(runtime::InstantRuntime, evidence = Dict{Symbol, Score}(),\n    size = 10, depth = 1, \n    order = topsort(get_initial_graph(get_network(runtime))),\n    placeholder_beliefs = get_placeholder_beliefs(runtime))\n\nSet the ranges of all current instances in the runtime.\n\nThis method first checks whether ranges exist for the runtime at the desired depth, with the desired range size, and with the same evidence. If so, it doesn't do anything. If the depth is less than 1, it doesn't do anything. Otherwise, it uses the support operator to compute ranges of variables in order. Placeholders should have ranges set already in placeholder_beliefs. For expanders, it recursively sets the ranges of the subnetworks at depth - 1.\n\nReturns a flag indicating whether any instance has a changed range.\n\n\n\n\n\n","category":"function"},{"location":"lib/models/#scruff_models","page":"Models","title":"Scruff.Models","text":"","category":"section"},{"location":"lib/models/","page":"Models","title":"Models","text":"    Modules = [Scruff.Models]","category":"page"},{"location":"lib/models/#Scruff.Models.FixedTimeModel","page":"Models","title":"Scruff.Models.FixedTimeModel","text":"abstract type FixedTimeModel{I,O} <: Model{I,O}\n\nA dynamic model described only for fixed time delta.  Must implement  get_initial, get_transition, and get_dt. These can depend on the current time.\n\n\n\n\n\n","category":"type"},{"location":"lib/models/#Scruff.Models.HomogeneousModel","page":"Models","title":"Scruff.Models.HomogeneousModel","text":"HomogeneousModel{I,O} <: FixedTimeModel{I,O}\n\nA dynamic model with a fixed time step and same transition model at every time point.. The constructor is called with the initial sfunc and transition sfuncs. The constructor is also called with an optional dt (defaults to 1).\n\n\n\n\n\n","category":"type"},{"location":"lib/models/#Scruff.Models.InstantModel","page":"Models","title":"Scruff.Models.InstantModel","text":"abstract type InstantModel{I,O} <: Model{I,Nothing,O}\n\nA model for a variable with no time dependencies. Since this model has no transitions, it can only called with  make_initial and not make_transition  (i.e. make_transition = make_initial)\n\n\n\n\n\n","category":"type"},{"location":"lib/models/#Scruff.Models.SimpleModel","page":"Models","title":"Scruff.Models.SimpleModel","text":"struct SimpleModel{I,O} <: TimelessInstantModel{I,O}\n\nA model that always produces the same SFunc. This is an TimelessInstantModel, so must always be called when the parents are the same time point. The constructor takes the sfunc as argument, which is stored. There is a convencience method to create a SimpleModel for any sfunc by applying the sfunc to zero arguments.\n\n\n\n\n\n","category":"type"},{"location":"lib/models/#Scruff.Models.StaticModel","page":"Models","title":"Scruff.Models.StaticModel","text":"struct StaticModel{I,O} <: VariableTimeModel{I,O,O} end\n\nA static model represents a variable that never changes its value. The value is setup through an sfunc created by make_initial. At any time point, it simply copies its previous value. Because it can be used flexibly, we make it a subtype of VariableTimeModel.\n\n\n\n\n\n","category":"type"},{"location":"lib/models/#Scruff.Models.TimelessFixedTimeModel","page":"Models","title":"Scruff.Models.TimelessFixedTimeModel","text":"abstract type TimelessFixedTimeModel{I,J,O} <: FixedTimeModel{I,J,O}\n\nA FixedTimeModel in which the initial and transition models do not depend on the current time. In addition to get_dt, must implement a version of get_initial and get_transition that do not take the current time as an argument.\n\n\n\n\n\n","category":"type"},{"location":"lib/models/#Scruff.Models.VariableTimeModel","page":"Models","title":"Scruff.Models.VariableTimeModel","text":"abstract type VariableTimeModel{I,J,O} <: Model{I,J,O}\n\nA model that creates sfuncs based on the time delta between the parents and the current instance. In general, the deltas can be different for different parents. This type does not introduce any new functionality over Model. Its purpose is to make explicit the fact that for this type of model, separate time deltas are possible. Must implement 'makeinitial', which takes the current time, and 'maketransition', which takes the current time and parent times. \n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#scruff_sfuncs","page":"Stochastic Functions","title":"Scruff.SFuncs","text":"","category":"section"},{"location":"lib/sfuncs/","page":"Stochastic Functions","title":"Stochastic Functions","text":"    Modules = [Scruff.SFuncs]","category":"page"},{"location":"lib/sfuncs/#Scruff.SFuncs.Apply","page":"Stochastic Functions","title":"Scruff.SFuncs.Apply","text":"Apply{J, O} <: SFunc{Tuple{SFunc{J, O}, J}, O}\n\nApply represents an sfunc that takes two groups of arguments.  The first group is a single argument, which is an sfunc to apply to the second group of arguments.\n\nAdditional supported operators\n\nsupport\nsupport_quality\nsample\nlogcpdf\ncompute_pi\nsend_lambda\n\nType parameters\n\nJ: the input type of the sfunc that may be applied; that sfunc is the input type of the Apply\nO: the output type of the sfunc that may be applied, which is also the output type of the Apply\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Cat","page":"Stochastic Functions","title":"Scruff.SFuncs.Cat","text":"mutable struct Cat{O} <: Dist{O, Vector{Real}}\n\nCat defines an sfunc that represents a set of categorical output values that are not conditioned on any input.  Its parameters are always of type Vector{Real}, which is the probability of each output value.\n\nSupported operations\n\nsupport\nsupport_quality\nsample\ncpdf\nbounded_probs\ncompute_pi\nf_expectation\n\nType parameters\n\nO: the output type of the Cat\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Chain","page":"Stochastic Functions","title":"Scruff.SFuncs.Chain","text":"struct Chain{I, J, K, O} <: Conditional{I, J, K, O, Nothing, Q, SFunc{J, O, Nothing}}\n\nA Conditional that chains its input I through a given function that returns an  SFunc{J,O}.\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Conditional","page":"Stochastic Functions","title":"Scruff.SFuncs.Conditional","text":"abstract type Conditional{I <: Tuple, J <: Tuple, K <: Tuple, O, S <: SFunc{J, O}} <: SFunc{K, O}\n\nConditional sfuncs represent the generation of an sfunc depending on the values of parents.  An subtype of Conditional must provide a gensf method that takes an I and returns an  SFunc{J,O} (important the generated SFunc must not appear outside the Conditional.  It should not be a parent).\n\nAdditional supported operators\n\nsupport\nsupport_quality\nsample\nlogcpdf\nmake_factors\ncompute_pi\nsend_lambda\n\nType parameters\n\nI: the type of data used to generate the Conditional's sfunc\nJ: a tuple that represents the input types (the I) of the Conditional's generated sfunc\nK: the input types of the Conditional; this is a tuple of types constructed from I, \n\nand J using extend_tuple_types\n\nO: the output type(s) of both the Conditional and the Conditional's generated sfunc\nS: the type of the Conditional's generated sfunc\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Constant","page":"Stochastic Functions","title":"Scruff.SFuncs.Constant","text":"mutable struct Constant{O} <: Dist{O,Nothing}\n\nConstant represents an sfunc that always produces the same value.  It has no inputs and no parameters.\n\nAdditional supported operators\n\nsupport\nsupport_quality\nsample\nlogcpdf\nbounded_probs\ncompute_pi\n\nType parameters\n\nO: the output type(s) of the Constant\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Det","page":"Stochastic Functions","title":"Scruff.SFuncs.Det","text":"abstract type Det{I, O} <: SFunc{I, O}\n\nDet defines an sfunc that represents a deterministic function I -> O.  When a Det is subtyped, a function apply(d::Det, i::I)::O or apply(d::Det, i::I...)::O must also be implemented.  It has no parameters.\n\nAdditional supported operators\n\nsupport\nsupport_quality\nsample\nlogcpdf\nbounded_probs\nmake_factors\ncompute_pi\nsend_lambda\n\nType parameters\n\nI: the input type(s) of the Det\nO: the output type(s) of the Det\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Expander","page":"Stochastic Functions","title":"Scruff.SFuncs.Expander","text":"mutable struct Expander{I,O} <: SFunc{I,O}\n\nAn Expander represents a model defined by a function that returns a network. For a given value of an input, the conditional probability distribution is provided by the network produced by the function on that input.\n\nFor each such network, the expander manages a runtime to reason about it. Expanders are lazy and do not evaluate the function until they have to.\n\nAs a result, there is state associated with Expanders. This is analysis state rather than world state, i.e., it is the state of Scruff's reasoning about the Expander. In keeping with Scruff design, Expanders are immutable and all state associated with reasoning is stored in the runtime that contains the expander. To support this, a runtime has three fields of global state:\n\n:subnets: the expansions of all Expanders managed by the runtime\n:subruntimes: all the subruntimes recursively managed by this runtime through Expanders, keyed by the networks\n:depth: the depth to which Expanders in this runtime should be expanded\n\nType parameters\n\nI: the input type(s) of the Expander\nO: the output type(s) of the Expander\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.ExplicitDet","page":"Stochastic Functions","title":"Scruff.SFuncs.ExplicitDet","text":"struct ExplicitDet{I, O} <: Det{I, O}\n\nExplicitDet is a Det that contains a field f::Function.  It also has an apply method that simply delegates to the ExplicitDet's function:\n\n    apply(d::ExplicitDet, i...) = d.f(i...)\n\njulia> d = ExplicitDet{Tuple{Vararg{Real}},Real}(sum)\nExplicitDet{Tuple{Vararg{Real, N} where N}, Real}(sum)\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Extend","page":"Stochastic Functions","title":"Scruff.SFuncs.Extend","text":"struct Extend{I<:Tuple{Any},J,O} <: SFunc{J,O}\n\nExtend defines an sfunc that extend the input of another sfunc. Useful for defining Separable SFuncs.\n\nAdditional supported operators\n\nsupport\nsupport_quality\nsample\nlogcpdf\nbounded_probs\nmake_factors\ncompute_pi\nsend_lambda\n\nType parameters\n\nI: the input type(s) of the extended sfunc; it must be a tuple of length 1\nJ: the input type(s) of the Extend\nO: the output type(s) of both the Extend and the extended sfunc \n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.FunctionalScore","page":"Stochastic Functions","title":"Scruff.SFuncs.FunctionalScore","text":"struct FunctionalScore{I} <: Score{I}\n\nA score defined by a function.\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Generate","page":"Stochastic Functions","title":"Scruff.SFuncs.Generate","text":"Generate{O} <: SFunc{Tuple{Dist{O}}, O}\n\nGenerate a value from its Dist argument.\n\nThis helps in higher-order programming. A typical pattern will be to create an sfunc that produces a Dist, and then generate many observations from the Dist using Generate.\n\nAdditional supported operators\n\nsupport\nsupport_quality\nsample\nlogcpdf\ncompute_pi\nsend_lambda\nmake_factors\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.HardScore","page":"Stochastic Functions","title":"Scruff.SFuncs.HardScore","text":"HardScore{I} <: Score{I}\n\nA fixed score.\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Invertible","page":"Stochastic Functions","title":"Scruff.SFuncs.Invertible","text":"struct Invertible{I,O} <: SFunc{Tuple{I},O}\n\nAn invertible sfunc, with both a forward and a inverse function provided.\n\nAdditional supported operators\n\nsupport\nsupport_quality\nsample\nlogcpdf\nbounded_probs\nmake_factors\ncompute_pi\nsend_lambda\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.LinearGaussian","page":"Stochastic Functions","title":"Scruff.SFuncs.LinearGaussian","text":"mutable struct LinearGaussian{I <: Tuple{Vararg{Float64}}} <: \n    Conditional{I, Tuple{}, I, Float64, Normal}\n\nLinearGaussian defines an sfunc whose mean is a linear function of its parents.  A  LinearGaussian's output type is a Float, its parameter type is  Tuple{I, Float64, Float64}, and it's contained sfunc is a Normal mean 0.0.\n\nType parameters\n\nI: the input type(s) of the LinearGaussian\n\nSee also: Conditional, Normal\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.LogScore","page":"Stochastic Functions","title":"Scruff.SFuncs.LogScore","text":"struct LogScore{I} <: Score{I}\n\nA Log score.\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Mixture","page":"Stochastic Functions","title":"Scruff.SFuncs.Mixture","text":"mutable struct Mixture{I,O} <: SFunc{I,O}\n\nMixture defines an sfunc representing mixtures of other sfuncs.  It contains a  vector of sfuncs and a vector of probabilities that those sfuncs are selected,  which indices are keys associating the two.  The output type of a Mixture is defined by the output type of its internal components.  The parameters of a Mixture are its probabilities followed by parameters of all its internal components, in order. \n\nAdditional supported operators\n\nsupport\nsupport_quality\nsample\ncpdf\nexpectation\ncompute_pi\nsend_lambda\n\nType parameters\n\nI: the input type(s) of the Mixture\nO: the shared output type(s) of its internal components and the output type(s) of the Mixture\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.NetworkSFunc","page":"Stochastic Functions","title":"Scruff.SFuncs.NetworkSFunc","text":"struct NetworkSFunc{I,O} <: SFunc{I,O}\n\nAn sfunc that combines multiple sfuncs in a network structure.\n\nArguments\n\ninput_placeholders A vector of placeholders indicating the types of network inputs. The type parameter `I` is computed from these.\nsfuncs The sfuncs to combine.\nparents A `Dict` that maps sfuncs to their parent sfuncs. Note that this parallels networks, \n     except that we are mapping sfuncs to lists of sfuncs directly rather than variables to vectors of variables.\noutput A vector of output sfuncs, determining the `O` type parameter.\n\nAdditional supported operators\n\nsample\nsample_logcpdf\nlogcpdf\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Normal","page":"Stochastic Functions","title":"Scruff.SFuncs.Normal","text":"mutable struct Normal <: Dist{Float64}\n\nNormal defines an sfunc representing unconditional Gaussian distributions.  Its has no input, its output type is Float64, and its parameters are (mean,standard deviation).\n\nAdditional supported operators\n\nsupport\nsupport_quality\nsample\nlogcpdf\nbounded_probs\ncompute_pi\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.NormalScore","page":"Stochastic Functions","title":"Scruff.SFuncs.NormalScore","text":"struct NormalScore <: Score{Float64}\n\nA score defined by a normal density given the mean and sd of the score.\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Parzen","page":"Stochastic Functions","title":"Scruff.SFuncs.Parzen","text":"struct Parzen <: Score{Float64}\n\nA parzen score.\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.SepCPTs","page":"Stochastic Functions","title":"Scruff.SFuncs.SepCPTs","text":"SepCPTs = Array{Dict{I, Array{Float64, 1}} where I}\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Serial","page":"Stochastic Functions","title":"Scruff.SFuncs.Serial","text":"struct Serial{I,O} <: SFunc{I,O}\n\nA sequence of sfuncs in series.\n\nAlthough this could be implemented as a special case of NetworkSFunc, the serial composition allows an easier and more efficient implementation of operations. All but the first sfunc in the sequence will have a single input; the output of each sfunc feeds into the input of the next sfunc.\n\nTo work properly, most of the operations on Serial need the support of the intermediate sfuncs, given an input range. Rather than compute this each time, and to avoid having the non-support operations take a size argument, support is memoized, and must be called before other operations like logcpdf are called. The support_memo is a dictionary whose keys are tuples of parent ranges and whose values are the support computed for those parent ranges, along with the target size for which they were computed. Storing the target size enables refinement algorithms that increase the size and improve  the support.\n\nAdditional supported operators\n\nsupport\nsupport_quality\nsample\ncpdf\nbounded_probs\nmake_factors\ncompute_pi\nsend_lambda\n\nType parameters\n\nI the input type of the first sfunc\nO the output type of the last sfunc\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Switch","page":"Stochastic Functions","title":"Scruff.SFuncs.Switch","text":"abstract type Switch{N, I, K, O} <: Det{K, O}\n\nSwitch defines an sfunc that represents choosing between multiple incoming (parent) Sfuncs  based on a test.  A subtype of Switch must provide a choose function that takes the switch  and an i and returns an integer between 1 and N.  This is an index into a 'parent array'.\n\nK must be a flat tuple type consisting of I and N occurrences of O:  for example, if I is Int\n\n    K = extend_tuple_type(Tuple{Int}, NTuple{N, O})\n\nIf the subtype'd sfunc is not in the Scruff.SFuncs module, the system must  import Scruff.SFuncs: choose.\n\nAdditional supported operators\n\nsupport\nsupport_quality\ncompute_pi\nsend_lambda\n\nType parameters\n\nN: the count of sfuncs from which to choose\nI: the type of the second argument of the choose function defined for the Switch\nK: the input type of the Switch; see above\nO: the output type of the Switch \n\nSee also:  choose, extend_tuple_type\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.Table","page":"Stochastic Functions","title":"Scruff.SFuncs.Table","text":"mutable struct Table{NumInputs, I <: NTuple{NumInputs, Any}, J, K, O, S <: SFunc{J,O}} <: Conditional{I, J, K, O, S}\n\nTable defines a Conditional whose function is given by a multi-dimensional table of type  Array{Q, NumInputs}, where Q is the output type of the internal sfunc and NumInputs is the count of incoming parent values.\n\nSee also:  Conditional, DiscreteCPT, CLG\n\n\n\n\n\n","category":"type"},{"location":"lib/sfuncs/#Scruff.SFuncs.CLG-Tuple{Dict}","page":"Stochastic Functions","title":"Scruff.SFuncs.CLG","text":"CLG(paramdict::Dict)\n\nConstructs an*sfunc representing a Conditional linear Gaussian.  These sfuncs may have  both discrete and continuous parents.  For each combination of discrete parents, there is  a LinearGaussian that depends on the continuous parents.\n\nCLGs are implemented as a Table with a LinearGaussian.\n\nThe paramdict parameter defines the discrete and continuous parents, and the linear  gaussean values where the length of a key is the count of the discrete inputs, the  length of the tuple in a value is the count of continuous inputs, and the rest of the values are used to build the parameters for CLG itself.  For example,\n\n    Dict((:x,1) => ((-1.0, 1.0, 2.0), 3.0, 1.0), \n         (:x,2) => ((-2.0, 4.0, 2.0), 3.0, 1.0),\n         (:x,3) => ((-3.0, 2.0, 2.0), 3.0, 1.0), \n         (:y,1) => ((-4.0, 5.0, 2.0), 3.0, 1.0),\n         (:y,2) => ((-5.0, 3.0, 2.0), 3.0, 1.0), \n         (:y,3) => ((-6.0, 6.0, 2.0), 3.0, 1.0))\n\n- the keys define two(2) discrete parents, with values `[:x,:y]` and `[1,2,3]`\n- in the values, the first tuple defines three(3) continuous parents for each\n  underlying `LinearGausian`, with values `-1.0:-6.0`, `1.0:6.0`, and `2.0`\n- the values `3.0` and `1.0` are mean/stddev of the underlying `LinearGaussian`\n\nSee also: Table, LinearGaussian\n\n\n\n\n\n","category":"method"},{"location":"lib/sfuncs/#Scruff.SFuncs.DiscreteCPT-Union{Tuple{O}, Tuple{I}, Tuple{Vector{O}, Dict{I, Vector{Float64}}}} where {I<:Tuple, O}","page":"Stochastic Functions","title":"Scruff.SFuncs.DiscreteCPT","text":"function DiscreteCPT(range::Vector{O}, paramdict::Dict{I, Vector{Float64}}) where {I <: Tuple, O}\n\nConstructs an sfunc that represents a Discrete Conditional Probability table.\n\nDiscreteCPTs are implemented as a Table with a Cat.\n\nThe range parameter defines all the possible outputs of the DiscreteCPT.  The paramdict  parameter defines the input(s) and the actual CPT.  For example, \n\n    range = [1, 2]\n    paramdict = Dict((1,1) => [0.3, 0.7], (1,2) => [0.6, 0.4], (2,1) =>[0.4, 0.6],\n    (2,2) => [0.7, 0.3], (3,1) => [0.5, 0.5], (3,2) => [0.8, 0.2])\n\ncan create a DiscreteCPT which has two(2) inputs (the length of the key) and, given each input as defined by the key, selects either 1 or 2 (the range) with the given probability.  So, if the input is (2,1), 1 is selected with probability 0.4 and 2 is selected with probability 0.6.\n\nSee also: Table, Cat\n\n\n\n\n\n","category":"method"},{"location":"lib/sfuncs/#Scruff.SFuncs.Flip-Tuple{Any}","page":"Stochastic Functions","title":"Scruff.SFuncs.Flip","text":"Flip(p)\n\nConstructs a very simple sfunc corresponding to a Bernoulli distribution,  represented by a Cat.  The output is true with probability p, and false with probability 1-p.\n\nSee also: Cat\n\n\n\n\n\n","category":"method"},{"location":"lib/sfuncs/#Scruff.SFuncs.Separable-Union{Tuple{O}, Tuple{Vector{O}, Vector{Float64}, Array{Dict{I, Vector{Float64}} where I}}} where O","page":"Stochastic Functions","title":"Scruff.SFuncs.Separable","text":"function Separable(range::Vector{O}, probabilities :: Vector{Float64}, compparams :: SepCPTs) where O\n\nConstructs an sfunc representing separable models, defined by additive decompositon of a conditional probability distribution into separate distributions depending on each of the parents.\n\nSeparables are implemented as a Mixture of Extend sfuncs that extend DiscreteCPTs.\n\nTo construct a Separable, this method is passed the range of output values, the probabilities of each of the underlying DiscreteCPT (which are the internal sfuncs of the Mixture), and the parameters for each of the DiscreteCPTs.  For example, \n\nalphas = [0.2, 0.3, 0.5]\ncpd1 = Dict((1,) => [0.1, 0.9], (2,) => [0.2, 0.8])\ncpd2 = Dict((1,) => [0.3, 0.7], (2,) => [0.4, 0.6], (3,) => [0.5, 0.5])\ncpd3 = Dict((1,) => [0.6, 0.4], (2,) => [0.7, 0.3])\ncpds :: Array{Dict{I,Array{Float64,1}} where I,1} = [cpd1, cpd2, cpd3]\ns = Separable([1, 2], alphas, cpds)\n\nSee also:  Mixture, Extend, DiscreteCPT, Table\n\n\n\n\n\n","category":"method"},{"location":"lib/sfuncs/#Scruff.SFuncs.SoftScore-Union{Tuple{Dict{I, Float64}}, Tuple{I}} where I","page":"Stochastic Functions","title":"Scruff.SFuncs.SoftScore","text":"SoftScore(scores::Dict{I,Float64})\n\nReturn a LogScore of the keys and log values in score.\n\n\n\n\n\n","category":"method"},{"location":"lib/sfuncs/#Scruff.SFuncs.SoftScore-Union{Tuple{I}, Tuple{Vector{I}, Vector{Float64}}} where I","page":"Stochastic Functions","title":"Scruff.SFuncs.SoftScore","text":"SoftScore(vs::Vector{I}, ss::Vector{Float64})\n\nReturn a LogScore of the log values in ss vector for  the associated keys in vs.\n\n\n\n\n\n","category":"method"},{"location":"lib/sfuncs/#Scruff.SFuncs.choose","page":"Stochastic Functions","title":"Scruff.SFuncs.choose","text":"choose interface.  For every subtype of Switch, an implementation of this method must be created, whose first parameter is the subtype, and the second parameter is of type I for the parameter type in Switch.\n\nFor example, the definition of the If sfunc is as follows, where choose returns either index 1 or index 2.\n\nstruct If{O} <: Switch{2, Bool, Tuple{Bool, O, O}, O} end\nchoose(::If, b::Bool) = b ? 1 : 2\n\n\n\n\n\n","category":"function"},{"location":"lib/sfuncs/#Scruff.SFuncs.dist-Tuple{Any}","page":"Stochastic Functions","title":"Scruff.SFuncs.dist","text":"returns a Distributions.Normal from a Scruff.SFuncs.Normal\n\n\n\n\n\n","category":"method"},{"location":"lib/sfuncs/#Scruff.SFuncs.extend_tuple_type-Tuple{Any, Any}","page":"Stochastic Functions","title":"Scruff.SFuncs.extend_tuple_type","text":"extend_tuple_type(T1, T2)\n\nGiven two types T1 and T2, concatenate the types into a single tuple type.  \n\nArguments\n\nT1: Any type\nT2: A tuple type\n\nReturns\n\nIf T1 is a tuple type, a tuple with the concatenation of the types in T1 and T2\nIf T1 is not a tuple type, a tuple with T1 prepended to the types in T2\n\nExamples\n\njulia> extend_tuple_type(Int64, Tuple{Float64})\nTuple{Int64, Float64}\n\njulia> extend_tuple_type(Tuple{Int64}, Tuple{Float64})\nTuple{Int64, Float64}\n\njulia> extend_tuple_type(Tuple{Vector{Float64}}, Tuple{Symbol,Symbol})     \nTuple{Vector{Float64}, Symbol, Symbol}\n\n\n\n\n\n","category":"method"},{"location":"lib/sfuncs/#Scruff.SFuncs.mean-Tuple{Scruff.SFuncs.Normal}","page":"Stochastic Functions","title":"Scruff.SFuncs.mean","text":"returns the mean of the Normal\n\n\n\n\n\n","category":"method"},{"location":"lib/sfuncs/#Scruff.SFuncs.sd-Tuple{Scruff.SFuncs.Normal}","page":"Stochastic Functions","title":"Scruff.SFuncs.sd","text":"returns the standard deviation of the Normal\n\n\n\n\n\n","category":"method"},{"location":"lib/utilities/#scruff_utils","page":"Utilities","title":"Scruff.Utils","text":"","category":"section"},{"location":"lib/utilities/","page":"Utilities","title":"Utilities","text":"    Modules = [Scruff.Utils]","category":"page"},{"location":"lib/utilities/#Scruff.Utils.Factor","page":"Utilities","title":"Scruff.Utils.Factor","text":"struct Factor{N}\n\nRepresentation of a factor over N instances.\n\narguments\n\ndims a tuple of dimensions of the instances\nkeys ids of the instances\nentries a vector of factor values\n\n\n\n\n\n","category":"type"},{"location":"lib/utilities/#Scruff.Utils.Graph","page":"Utilities","title":"Scruff.Utils.Graph","text":"struct Graph\n\nA simple graph with nodes (Int), edges (outgoing), and a size property for each node\n\n\n\n\n\n","category":"type"},{"location":"lib/utilities/#Base.show-Tuple{Scruff.Utils.Factor{0}}","page":"Utilities","title":"Base.show","text":"function show(f::Factor)\n\nPrint the factor in an easy to read format.\n\n\n\n\n\n","category":"method"},{"location":"lib/utilities/#Scruff.Utils.bounded_linear_value-Tuple{Any, Any, Any}","page":"Utilities","title":"Scruff.Utils.bounded_linear_value","text":"bounded_linear_value(weights, bias, interval_combo)\n\nWeight and sum the upper and lower bounds in interval_combo with the given bias\n\n\n\n\n\n","category":"method"},{"location":"lib/utilities/#Scruff.Utils.cartesian_product-Tuple{Tuple}","page":"Utilities","title":"Scruff.Utils.cartesian_product","text":"cartesian_product(xs::Tuple)\ncartesian_product(xs::Array)\n\nGiven an array of arrays, returns the cartesian product of those arrays.\n\nExamples\n\njulia> cartesian_product([[1,2],[3,4]])\n4-element Array{Array{Int64,1},1}:\n [1, 3]\n [1, 4]\n [2, 3]\n [2, 4]\n\njulia> cartesian_product([[1,2],[3,4],[5,6]])\n8-element Array{Array{Int64,1},1}:\n [1, 3, 5]\n [1, 3, 6]\n [1, 4, 5]\n [1, 4, 6]\n [2, 3, 5]\n [2, 3, 6]\n [2, 4, 5]\n [2, 4, 6]\n\n\n\n\n\n","category":"method"},{"location":"lib/utilities/#Scruff.Utils.linear_value-Tuple{Any, Any, Any}","page":"Utilities","title":"Scruff.Utils.linear_value","text":"linear_value(weights, bias, continuous_combo)\n\nWeight and sum the continuous_combo with the given bias\n\n\n\n\n\n","category":"method"},{"location":"lib/utilities/#Scruff.Utils.make_intervals-Tuple{Any}","page":"Utilities","title":"Scruff.Utils.make_intervals","text":"make_intervals(range)\n\nGiven a range of values of a continuous variable, create interval bins surrounding the values\n\n\n\n\n\n","category":"method"},{"location":"lib/utilities/#Scruff.Utils.memo-Tuple{Function}","page":"Utilities","title":"Scruff.Utils.memo","text":"memo(f::Function)\n\nreturns a memoized one argument function\n\n\n\n\n\n","category":"method"},{"location":"lib/utilities/#Scruff.Utils.nextkey","page":"Utilities","title":"Scruff.Utils.nextkey","text":"nextkey()::Int\n\nProduce a fresh instance id that does not conflict with an existing id.\n\n\n\n\n\n","category":"function"},{"location":"lib/utilities/#Scruff.Utils.normal_density-Tuple{Any, Any, Any}","page":"Utilities","title":"Scruff.Utils.normal_density","text":"normal_density(x, mean, variance)\n\nGet the normal density of x\n\n\n\n\n\n","category":"method"},{"location":"lib/utilities/#Scruff.Utils.normalize-Tuple{Any}","page":"Utilities","title":"Scruff.Utils.normalize","text":"normalize(xs)\n\nNormalize an array of non-negative reals to sum to 1\n\n\n\n\n\n","category":"method"},{"location":"lib/utilities/#Scruff.Utils.normalize-Tuple{Scruff.Utils.Factor}","page":"Utilities","title":"Scruff.Utils.normalize","text":"function normalize(f::Factor)\n\nReturn a new factor equal to the given factor except that entries sum to 1\n\n\n\n\n\n","category":"method"},{"location":"lib/utilities/#Scruff.Utils.normalized_product-Tuple{Any, Any}","page":"Utilities","title":"Scruff.Utils.normalized_product","text":"normalized_product(xss, n)\n\nCompute the product of the given arrays of length n and normalize the result.  Uses log computations to avoid underflow.\n\n\n\n\n\n","category":"method"},{"location":"lib/utilities/#Scruff.Utils.topsort-Union{Tuple{Dict{U, Vector{U}}}, Tuple{U}} where U","page":"Utilities","title":"Scruff.Utils.topsort","text":"topsort(graph::Dict{T, Vector{T}}) :: Vector{T} where T\n\nPerforms a topological sort on the given graph. In a cyclic graph, the order of variables in the cycle is arbitrary, but they will be correctly sorted relative to other variables.\n\n\n\n\n\n","category":"method"},{"location":"#Scruff","page":"Getting Started","title":"Scruff","text":"","category":"section"},{"location":"","page":"Getting Started","title":"Getting Started","text":"Scruff is an AI framework to build agents that sense, reason, and learn in the world using a variety of models.   It aims to integrate many different kinds of models in a coherent framework, provide flexibility in spatiotemporal modeling, and provide tools to compose, share, and reuse models and model components.","category":"page"},{"location":"","page":"Getting Started","title":"Getting Started","text":"Warning: Scruff is rapidly evolving beta research software. Although the software already has a lot of functionality, we intend to expand on this in the future and cannot promise stability of the code or the APIs at the moment.","category":"page"},{"location":"#Installation","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"","page":"Getting Started","title":"Getting Started","text":"First, download Julia 1.6.0 or later.","category":"page"},{"location":"","page":"Getting Started","title":"Getting Started","text":"Then, install the Scruff package with the Julia package manager.  From the Julia REPL, type ] to enter the Pkg REPL mode and then run:","category":"page"},{"location":"","page":"Getting Started","title":"Getting Started","text":"pkg> add Scruff","category":"page"},{"location":"#Developing-Scruff","page":"Getting Started","title":"Developing Scruff","text":"","category":"section"},{"location":"","page":"Getting Started","title":"Getting Started","text":"To develop Scruff, first pull down the code","category":"page"},{"location":"","page":"Getting Started","title":"Getting Started","text":"$ git clone https://github.com/p2t2/Scruff.git","category":"page"},{"location":"#Learning-about-Scruff","page":"Getting Started","title":"Learning about Scruff","text":"","category":"section"},{"location":"","page":"Getting Started","title":"Getting Started","text":"Please read the The Scruff Tutorial, which describes most of the language features through examples. The library documentation contains detailed information about most of the data structures and functions used in the code.","category":"page"},{"location":"#Contributing-to-Scruff","page":"Getting Started","title":"Contributing to Scruff","text":"","category":"section"},{"location":"","page":"Getting Started","title":"Getting Started","text":"We welcome contributions from the community. Please see the issues in Github for some of the improvements  we would like to make, and feel free to add your own suggestions. ","category":"page"},{"location":"lib/operators/#scruff_operators","page":"Operators","title":"Scruff.Operators","text":"","category":"section"},{"location":"lib/operators/","page":"Operators","title":"Operators","text":"    Modules = [Scruff.Operators]","category":"page"},{"location":"lib/operators/#Scruff.Operators","page":"Operators","title":"Scruff.Operators","text":"The Operators module defines the following interfaces for the following operators:\n\nis_deterministic(sf::SFunc)::Bool\nsample(sf::SFunc{I,O}, i::I)::O where {I,O}\nsample_logcpdf(sf::SFunc{I,O}, i::I)::Tuple{O, AbstractFloat} where {I,O}\ninvert(sf::SFunc{I,O}, o::O)::I where {I,O}\nlambda_msg(sf::SFunc{I,O}, i::SFunc{<:__Opt{Tuple{}}, O})::SFunc{<:__Opt{Tuple{}}, I} where {I,O}\nmarginalize(sf::SFunc{I,O}, i::SFunc{<:__Opt{Tuple{}}, I})::SFunc{<:__Opt{Tuple{}}, O} where {I,O}\nlogcpdf(sf::SFunc{I,O}, i::I, o::O)::AbstractFloat where {I,O}\ncpdf(sf::SFunc{I,O}, i::I, o::O)::AbstractFloat where {I,O}\nlog_cond_prob_plus_c(sf::SFunc{I,O}, i::I, o::O)::AbstractFloat where {I,O}\nf_expectation(sf::SFunc{I,O}, i::I, fn::Function) where {I,O}\nexpectation(sf::SFunc{I,O}, i::I)::O where {I,O}\nvariance(sf::SFunc{I,O}, i::I)::O where {I,O}\nget_params(sf::SFunc{I,O,P})::P where {I,O,P}\nset_params!(sf::SFunc{I,O,P}, p::P)::SFunc{I,O,P} where {I,O,P}\nget_score(sf::SFunc{Tuple{I},O}, i::I)::AbstractFloat where {I,O}\nget_log_score(sf::SFunc{Tuple{I},O}, i::I)::AbstractFloat where {I,O}\nsupport(sf::SFunc{I,O},                        parranges::NTuple{N,Vector},                        size::Integer,                        curr::Vector{<:O}) where {I,O,N}\nsupport_quality(sf::SFunc, parranges)\nbounded_probs(sf::SFunc{I,O},                             range::__OptVec{<:O},                             parranges::NTuple{N,Vector})::Tuple{Vector{<:AbstractFloat}, Vector{<:AbstractFloat}} where {I,O,N}\nmake_factors(sf::SFunc{I,O},                           range::__OptVec{<:O},                            parranges::NTuple{N,Vector},                            id,                            parids::Tuple)::Tuple{Vector{<:Scruff.Utils.Factor}, Vector{<:Scruff.Utils.Factor}} where {I,O,N}\ninitial_stats(sf::SFunc)\nexpected_stats(sf::SFunc{I,O},                             range::__OptVec{<:O},                              parranges::NTuple{N,Vector},                             pis::NTuple{M,Dist},                             child_lambda::Score{<:O}) where {I,O,N,M}\naccumulate_stats(sf::SFunc, existing_stats, new_stats)\nmaximize_stats(sf::SFunc, stats)\ncompute_bel(sf::SFunc{I,O},                         range::__OptVec{<:O},                          pi::Dist{<:O},                          lambda::Score{<:O})::Dist{<:O} where {I,O}\ncompute_lambda(sf::SFunc, range::__OptVec, lambda_msgs::Vector{<:Score})::Score\nsend_pi(sf::SFunc{I,O},                      range::__OptVec{O},                       bel::Dist{O},                       lambda_msg::Score{O})::Dist{<:O} where {I,O}\noutgoing_pis(sf::SFunc,                           range::__OptVec,                            bel::Dist,                            incoming_lambdas::__OptVec{<:Score})::Vector{<:Dist}\noutgoing_lambdas(sf::SFunc{I,O},                     lambda::Score{O},                     range::__OptVec{O},                     parranges::NTuple{N,Vector},                     incoming_pis::Tuple)::Vector{<:Score} where {N,I,O}\ncompute_pi(sf::SFunc{I,O},                        range::__OptVec{O},                         parranges::NTuple{N,Vector},                         incoming_pis::Tuple)::Dist{<:O} where {N,I,O}\nsend_lambda(sf::SFunc{I,O},                          lambda::Score{O},                          range::__OptVec{O},                          parranges::NTuple{N,Vector},                          incoming_pis::Tuple,                          parent_idx::Integer)::Score where {N,I,O}\n\n\n\n\n\n","category":"module"},{"location":"lib/operators/#Scruff.Operators.__Opt","page":"Operators","title":"Scruff.Operators.__Opt","text":"__Opt{T} = Union{Nothing, T}\n\n\n\n\n\n","category":"type"},{"location":"lib/operators/#Scruff.Operators.__OptVec","page":"Operators","title":"Scruff.Operators.__OptVec","text":"__OptVec{T} = Union{Vector{Union{}}, Vector{T}}\n\n\n\n\n\n","category":"type"},{"location":"lib/operators/#Scruff.Operators.export_operators-Tuple{}","page":"Operators","title":"Scruff.Operators.export_operators","text":"export_operators()\n\nExports all the functions defined in Operators.\n\n\n\n\n\n","category":"method"},{"location":"lib/operators/#Scruff.Operators.module_functions-Tuple{Any}","page":"Operators","title":"Scruff.Operators.module_functions","text":"module_functions(mod)\n\nReturns the name of all the functions in the given module.\n\n\n\n\n\n","category":"method"},{"location":"lib/operators/#Scruff.Operators.support_quality_from_rank-Tuple{Int64}","page":"Operators","title":"Scruff.Operators.support_quality_from_rank","text":"support_quality_from_rank(rank::Int)\n\nConvert the rank back into the support quality.\n\n\n\n\n\n","category":"method"},{"location":"lib/operators/#Scruff.Operators.support_quality_rank-Tuple{Symbol}","page":"Operators","title":"Scruff.Operators.support_quality_rank","text":"support_quality_rank(sq::Symbol)\n\nConvert the support quality symbol into an integer for comparison.\n\n\n\n\n\n","category":"method"},{"location":"lib/operators/#Scruff.Operators.@import_operators-Tuple{}","page":"Operators","title":"Scruff.Operators.@import_operators","text":"import_operators()\n\nImports all the functions defined in Operators\n\n\n\n\n\n","category":"macro"},{"location":"lib/algorithms/#scruff_algorithms","page":"Algorithms","title":"Scruff.Algorithms","text":"","category":"section"},{"location":"lib/algorithms/","page":"Algorithms","title":"Algorithms","text":"    Modules = [Scruff.Algorithms]","category":"page"},{"location":"lib/algorithms/#Scruff.Algorithms.Queryable","page":"Algorithms","title":"Scruff.Algorithms.Queryable","text":"A query target is either a variable instance or a variable. Allowing queries to be defined in terms of instances rather than variables makes it possible to ask queries across multiple instances of a variable at different times. However, in many cases the current instance of the variable(s) is required and then it is easier to use variables.\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.Algorithm","page":"Algorithms","title":"Scruff.Algorithms.Algorithm","text":"Algorithm\n\nThe supertype of all algorithms.\n\nA standard set of queries is defined for algorithms. Any given subtype of Algorithm will implement a subset of these queries.\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.BP","page":"Algorithms","title":"Scruff.Algorithms.BP","text":"abstract type BP <: InstantAlgorithm\n\nBelief Propagation algorithm\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.CoherentWindow","page":"Algorithms","title":"Scruff.Algorithms.CoherentWindow","text":"struct CoherentWindow <: WindowCreator end\n\nA variant of AsyncWindow that ensures that parent values are never stale for any variable that gets updated in a filter step. In other words, if any parent of a direct parent has been updated more recently than a variable to be updated, the direct parent is added to the variables to be updated. This condition then recurses for the direct parents.\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.Filter","page":"Algorithms","title":"Scruff.Algorithms.Filter","text":"abstract type Filter <: Algorithm end\n\nGeneral type of filtering algorithms.\n\nMust implement initfilter and filterstep methods.\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.Importance","page":"Algorithms","title":"Scruff.Algorithms.Importance","text":"Importance <: InstantAlgorithm\n\nRepresentation of an importance sampling algorithm.\n\narguments\n\nproposal_function Specifies how the algorithm should make proposals. This is a function\n\nthat takes a runtime and an instance and returns a proposer.  The proposer takes parent values and proposes a value for the instance along with a log score.\n\nnum_particles The number of completed particles to use. This is not necessarily the\n\nnumber attempted. If there are rejections, the algorithm will continue to create particles until num_particles have been completed. Warning: With impossible evidence, the process will not terminate.\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.InstantAlgorithm","page":"Algorithms","title":"Scruff.Algorithms.InstantAlgorithm","text":"InstantAlgorithm\n\nAlgorithm that runs once on an `InstantNetwork`.\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.IterativeAlgorithm","page":"Algorithms","title":"Scruff.Algorithms.IterativeAlgorithm","text":"abstract type IterativeAlgorithm <: InstantAlgorithm\n\nAlgorithm that runs iteratively on an InstantNetwork.\n\nThe algorithm should support two methods: prepare and refine.\n\nAn IterativeAlgorithm is also trivially an InstantAlgorithm where Infer is implemented by calling prepare and refine once.\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.IterativeSampler","page":"Algorithms","title":"Scruff.Algorithms.IterativeSampler","text":"struct IterativeSampler <: IterativeAlgorithm\n\nAn iterative algorithm that uses a sampler to accumulate more samples on each refinement.\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.LazyInference","page":"Algorithms","title":"Scruff.Algorithms.LazyInference","text":"struct LazyInference <: IterativeAlgorithm\n\nAn iterative algorithm that expands recursively and increases the ranges of instances on every iteration.\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.LazyState","page":"Algorithms","title":"Scruff.Algorithms.LazyState","text":"mutable struct LazyState\n\nMaintains the state of a lazy algorithm\n\nFields\n\nprevious_algorithm: The last instant algorithm used, if any\nevidence: The evidence supplied in prepare\ninterventions: The interventions supplied in prepare\nplaceholder_beliefs: The placeholder beliefs supplied in prepare\nnext_size: The range size to use in the next call to refine\nnext_depth: The depth to use in the next call to refine\nnext_iteration: The number of the next iteration\nis_complete: A flag indicating whether the netwowk has been fully expanded\norder: The order of nodes used in computations\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.LazyState-NTuple{4, Any}","page":"Algorithms","title":"Scruff.Algorithms.LazyState","text":"LazyState(ns, nd, ni, ic)\n\nIntantiate LazyState with next_size, next_depth, next_iterator, and is_complete. \n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.LoopyBP","page":"Algorithms","title":"Scruff.Algorithms.LoopyBP","text":"LoopyBP\n\nAn instant algorithm that runs loopy belief propagation.\n\nArguments\n\ndefaultrangesize: The size to use as default when calling support on a node.\nepsilon: The allowable difference between beliefs on successive iterations \n\nfor termination.\n\nmaxiterations: The maximum number of iterations to run. infer will terminate if \n\nthis number of iterations is reached, even if it has not converged.\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.Particles","page":"Algorithms","title":"Scruff.Algorithms.Particles","text":"struct Particles\n\nA structure of particles containing a vector of Samples and of log_weights. \n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.Query","page":"Algorithms","title":"Scruff.Algorithms.Query","text":"abstract type Query end\n\nGeneral type of query that can be answered after running an algorithm.\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.Sample","page":"Algorithms","title":"Scruff.Algorithms.Sample","text":"Sample = Dict{Symbol, Any}\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.ThreePassBP","page":"Algorithms","title":"Scruff.Algorithms.ThreePassBP","text":"ThreePassBP\n\nAn instant algorithm that runs three passes of belief propagation.\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.VE","page":"Algorithms","title":"Scruff.Algorithms.VE","text":"VE(query_vars::Vector{Variable})\n\nAn instant algorithm that runs variable elimination.\n\nArguments\n\nnetwork\nquery_vars: The variables to query, which are not eliminated\ndepth: A depth of 1 means not to expand expanders, otherwise expands recursively to the given depth\nbounds: If true, return lower and upper bounds factors, otherwise just return a single factor\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.WindowFilter","page":"Algorithms","title":"Scruff.Algorithms.WindowFilter","text":"struct WindowFilter <: Filter\n\nGeneral construction for a filter based on a flexible windowing scheme.\n\n#arguments     windowcreator Defines the method used to create windows     inferencealgorithm Defines the algorithm to use on a window     postprocess! A postprocessing function, that takes the runtime and does any additional processing needed to carry to the next iteration. Defaults to doing nothing.\n\n\n\n\n\n","category":"type"},{"location":"lib/algorithms/#Scruff.Algorithms.AsyncBP","page":"Algorithms","title":"Scruff.Algorithms.AsyncBP","text":"AsyncBP(range_size = 10, T = Float64)\n\nA window filter that uses an asynchronous window with ThreePassBP with the given range size. T represents the time type and must be the same as used in creation of the runtime.\n\n\n\n\n\n","category":"function"},{"location":"lib/algorithms/#Scruff.Algorithms.AsyncLoopy","page":"Algorithms","title":"Scruff.Algorithms.AsyncLoopy","text":"AsyncLoopy(range_size = 10, T = Float64)\n\nA window filter that uses an asynchronous window with LoopyBP with the given range size. T represents the time type and must be the same as used in creation of the runtime.\n\n\n\n\n\n","category":"function"},{"location":"lib/algorithms/#Scruff.Algorithms.AsyncPF","page":"Algorithms","title":"Scruff.Algorithms.AsyncPF","text":"AsyncPF(num_particles::Int, resampling_size::Int = num_particles, T = Float64)\n\nA particle filter that uses an asynchronous window with the given number of particles and resampling buffer size. T represents the time type and must be the same as used in creation of the runtime.\n\n\n\n\n\n","category":"function"},{"location":"lib/algorithms/#Scruff.Algorithms.CoherentBP","page":"Algorithms","title":"Scruff.Algorithms.CoherentBP","text":"CoherentBP(range_size = 10, T = Float64)\n\nA window filter that uses a coherent window with ThreePassBP with the given range size. T represents the time type and must be the same as used in creation of the runtime.\n\n\n\n\n\n","category":"function"},{"location":"lib/algorithms/#Scruff.Algorithms.CoherentLoopy","page":"Algorithms","title":"Scruff.Algorithms.CoherentLoopy","text":"CoherentLoopy(range_size = 10, T = Float64)\n\nA window filter that uses a coherent window with LoopyBP with the given range size. T represents the time type and must be the same as used in creation of the runtime.\n\n\n\n\n\n","category":"function"},{"location":"lib/algorithms/#Scruff.Algorithms.CoherentPF","page":"Algorithms","title":"Scruff.Algorithms.CoherentPF","text":"CoherentPF(num_particles::Int, resampling_size::Int = num_particles, T = Float64)\n\nA particle filter that uses a coherent window with the given number of particles and resampling buffer size. T represents the time type and must be the same as used in creation of the runtime.\n\n\n\n\n\n","category":"function"},{"location":"lib/algorithms/#Scruff.Algorithms.LSFI-Tuple{Any}","page":"Algorithms","title":"Scruff.Algorithms.LSFI","text":"function LSFI(query_vars; \n    increment = 10, start_size = increment, max_iterations = 100, start_depth = 1)\n\nA lazy inference algorithm that uses variable elimination at every step.\n\nArguments\n\nquery_vars: Variables that can be queried after each refine step\nincrement: The increment to range size on every iteration\nstart_size: The starting range size\nmax_iterations: The maximum number of refinement steps\nstart_depth: The depth of recursive expansion in the first iteration\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.SyncBP","page":"Algorithms","title":"Scruff.Algorithms.SyncBP","text":"SyncBP(range_size = 10)\n\nA window filter that uses a synchronous window with ThreePassBP with the given range size.\n\n\n\n\n\n","category":"function"},{"location":"lib/algorithms/#Scruff.Algorithms.SyncLoopy","page":"Algorithms","title":"Scruff.Algorithms.SyncLoopy","text":"SyncLoopy(range_size = 10)\n\nA window filter that uses a synchronous window with LoopyBP with the given range size.\n\n\n\n\n\n","category":"function"},{"location":"lib/algorithms/#Scruff.Algorithms.SyncPF","page":"Algorithms","title":"Scruff.Algorithms.SyncPF","text":"SyncPF(num_particles::Int, resampling_size::Int = num_particles)\n\nA particle filter that uses a synchronous window with the given number of particles and resampling buffer size.\n\n\n\n\n\n","category":"function"},{"location":"lib/algorithms/#Scruff.Algorithms.answer-Tuple{Scruff.Algorithms.Query, Scruff.Algorithms.Algorithm, Runtime, VariableInstance}","page":"Algorithms","title":"Scruff.Algorithms.answer","text":"answer(::Query, ::Algorithm, ::Runtime, ::VariableInstance)\nanswer(::Query, ::Algorithm, ::Runtime, ::Vector{VariableInstance})\nanswer(::Query, ::Algorithm, ::Runtime, ::Queryable)\nanswer(::Query, ::Algorithm, ::Runtime, ::Vector{Queryable})\n\nAnswer the query.\n\nAn implementation of an algorithm should implement an `answer` method for any queries\nit can handle. The type hierarchies of `Query` and `Algorithm` will enable\nquery answering methods to be used wherever appropriate with the right specialization.\nThe implementations of `answer` are differentiated along two dimensions:\n- single or multiple items\n- queryable items in general or specifically instances\n\nIt is expected that an algorithm will implement one of the first two methods for queries it\ncan handle. I.e., an algorithm is expected to handle a single instance or a vector of instances.\nIf it can handle multiple instances, it should implement a second method and a single instance implementation\nis derived by default using a singleton vector. An algorithm can still override this default\nmethod if it handles single instances differently from multiple.\n\nAlgorithms will generally not implement the latter two methods, which are provide for convenience. \nDefault implementations are provided that delegate to the instance-specific methods.\n\nDefining a very high-level default implementation that throws an error enables implementations\nto go through sequences of preferences.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.create_window-Tuple{Scruff.Algorithms.SyncWindow, Runtime, Vector{<:Variable}, Int64}","page":"Algorithms","title":"Scruff.Algorithms.create_window","text":"create_window(::SyncWindow, runtime::Runtime, variables::Vector{<:Variable}, time::Int)::Vector{Instance}\n\nCreates a window by instantiating all variables at all intermediate time steps from the earliest parent to the given time. The variables argument is ignored.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.dynamic_name_and_time","page":"Algorithms","title":"Scruff.Algorithms.dynamic_name_and_time","text":"Create a dynamic name and time from an instant node. T is the time type.\n\n\n\n\n\n","category":"function"},{"location":"lib/algorithms/#Scruff.Algorithms.effective_sample_size-Tuple{Vector{Float64}}","page":"Algorithms","title":"Scruff.Algorithms.effective_sample_size","text":"expected_sample_size(log_weights::Vector{Float64})\n\nEffective sample size\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.expectation-Tuple{Scruff.Algorithms.Algorithm, Runtime, Union{Variable{I, J, O}, VariableInstance{O}} where {O, I, J}, Function}","page":"Algorithms","title":"Scruff.Algorithms.expectation","text":"expectation(alg::Algorithm, runtime::Runtime, item::Queryable, f::Function)::Float64\n\nReturn the expectation of the function f over the marginal distribution of item.\n\nThe default implementation uses the expectation operation on the SFunc representing the marginal distribution.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.filter_step-Union{Tuple{T}, Tuple{Scruff.Algorithms.Filter, DynamicRuntime{T}, Vector{<:Variable}, T, Dict{Symbol, Score}}} where T","page":"Algorithms","title":"Scruff.Algorithms.filter_step","text":"filter_step(filter::Filter, runtime::Runtime, variables::Vector{Variable}, time::T, evidence::Dict{Symbol, Score})\n\nRun one step of the filter by instantiating the given variables at the given time and passing in the given evidence.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.init_filter!-Tuple{Scruff.Algorithms.Filter, DynamicRuntime}","page":"Algorithms","title":"Scruff.Algorithms.init_filter!","text":"init_filter!(::Filter, ::DynamicRuntime)\n\nAn interface for intializing the filter for a dynamic runtime.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.initial_instant_runtime-Tuple{DynamicRuntime}","page":"Algorithms","title":"Scruff.Algorithms.initial_instant_runtime","text":"Creates an instant runtime for the first time step.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.instant_name-Tuple{Symbol, Number}","page":"Algorithms","title":"Scruff.Algorithms.instant_name","text":"Create a name in an instant network corresponding to the given dynamic name and time.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.instant_node-Tuple{VariableInstance}","page":"Algorithms","title":"Scruff.Algorithms.instant_node","text":"Create an instant node from a dynamic variable instance.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.instant_node-Union{Tuple{PlaceholderInstance{O}}, Tuple{O}} where O","page":"Algorithms","title":"Scruff.Algorithms.instant_node","text":"Create an instant node from a dynamic placeholder instance.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.instant_runtime_from_instances-Tuple{DynamicRuntime, Vector{Instance}}","page":"Algorithms","title":"Scruff.Algorithms.instant_runtime_from_instances","text":"instant_runtime_from_instances(runtime::DynamicRuntime, instances::Vector{Instance})\n\nCreate an instant runtime from the given instances in the given dynamic runtime.\n\nThis runtime has an instant network that contains a variable for each instance in insts,  tagged with the time of the instance. The network also contains a placeholder for each instance in placeholder_insts. The function also instantiates the variables in the instant runtime and stores any runtime  values from the dynamic runtime with the corresponding instances in the instant runtime. This function is useful for running instant algorithms on a time window  for dynamic reasoning.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.joint-Tuple{Scruff.Algorithms.Algorithm, Runtime, Vector{Union{Variable{I, J, O}, VariableInstance{O}} where {O, I, J}}}","page":"Algorithms","title":"Scruff.Algorithms.joint","text":"joint(alg::Algorithm, run::Runtime, items::Vector{Queryable})::Union{Score{O}, Tuple{Score{O}, Score{O}}}\n\nReturn the joint distribution over items, or lower and upper distributions, depending on the algorithm.\n\nThe returned Score assigns a score for each Vector of values of the items.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.lw_proposal-Tuple{Runtime, VariableInstance}","page":"Algorithms","title":"Scruff.Algorithms.lw_proposal","text":"lw_proposal(runtime::Runtime, instance::VariableInstance, parent_values::Tuple)\n\nReturn a proposer and scorer to implement likelihood weighting.\n\nThis proposal scheme is the same as the prior proposal unless a variable has hard evidence. In the case of hard evidence, the proposer sets the value of the variable to the evidence value and scores it by the log conditional probability of the evidence given the parent values.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.make_custom_proposal-Tuple{Dict{Symbol, SFunc}}","page":"Algorithms","title":"Scruff.Algorithms.make_custom_proposal","text":"make_custom_proposal(custom_sfs::Dict{Symbol, SFunc})\n\nCreate a proposal function for a custom proposal scheme.\n\nReturns a proposal function that can be provided to the Importance constructor. Evidence is handled similar to lw, except that the custom proposal is used for soft evidence.\n\nArguments\n\ncustom_sfs A dictionary mapping variable names to custom sfuncs used for their proposal.\n\nNeed not be complete; if a variable is not in this dictionary, its standard sfunc will be used.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.marginal-Tuple{Scruff.Algorithms.Particles, Symbol}","page":"Algorithms","title":"Scruff.Algorithms.marginal","text":"marginal(parts::Particles, x::Symbol)::Cat\n\nReturns a Cat representing the marginal distribution over the given symbol according to parts\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.marginal-Union{Tuple{O}, Tuple{Scruff.Algorithms.Algorithm, Runtime, Union{Variable{I, J, O}, VariableInstance{O}} where {I, J}}} where O","page":"Algorithms","title":"Scruff.Algorithms.marginal","text":"marginal(alg::Algorithm, runtime::Runtime, item::Queryable{O})::Union{Dist{O}, Tuple{Dist{O}, Dist{O}}} where O\n\nReturn the marginal distribution over item, or lower and upper marginals, depending on the algorithm.\n\nThe returned Score assigns a score to each value of item.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.mean-Union{Tuple{O}, Tuple{Scruff.Algorithms.Algorithm, Runtime, Union{Variable{I, J, O}, VariableInstance{O}} where {I, J}}} where O<:Number","page":"Algorithms","title":"Scruff.Algorithms.mean","text":"mean(alg::Algorithm, runtime::Runtime, item::Queryable)\n\nReturn the mean of item.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.normalize_weights-Tuple{Vector{Float64}}","page":"Algorithms","title":"Scruff.Algorithms.normalize_weights","text":"normalize_weights(log_weights::Vector{Float64})\n\nNormalize weights\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.prepare-Tuple{Scruff.Algorithms.InstantAlgorithm, InstantRuntime, Vector{<:SFunc{Tuple{}}}, Vector{Tuple{Symbol, Score}}, Vector{Tuple{Symbol, SFunc{Tuple{}}}}}","page":"Algorithms","title":"Scruff.Algorithms.prepare","text":"prepare(algorithm::IterativeAlgorithm, runtime::InstantRuntime\n    evidence::Dict{Symbol, <:Score}, \n    interventions::Dict{Symbol, <:Dist},\n    placeholder_beliefs::Dict{Symbol, <:Dist})\n\nPrepare the inference algorithm for iteration.\n\nStores the algorithm state in runtime. \n\nArguments\n\nalgorithm: The iterative algorithm to run.\nruntime: The runtime in which to run the algorithm.\nevidence: The supplied evidence, which defaults to Dict(). \ninterventions: The supplied interventions, which defaults to Dict(). \nplaceholder_beliefs: The beliefs associated with the placeholders in the \n\nnetwork, which default to Dict(). \n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.probability-Tuple{Scruff.Algorithms.Algorithm, Runtime, Vector{Union{Variable{I, J, O}, VariableInstance{O}} where {O, I, J}}, Function}","page":"Algorithms","title":"Scruff.Algorithms.probability","text":"probability(alg::Algorithm, run::Runtime, items::Vector{Queryable}, predicate::Function)::Union{Float64, Tuple{Float64, Float64}}\n\nReturn the probability that items satisfy query or lower and upper probabilities.\n\npredicate is a function from Vector{Any} to Bool.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.probability-Tuple{Scruff.Algorithms.Particles, Function}","page":"Algorithms","title":"Scruff.Algorithms.probability","text":"probability(parts::Particles, predicate::Sample -> Bool)::Float64\n\nReturns the probability that the predicate is satisfied\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.probability-Union{Tuple{O}, Tuple{Scruff.Algorithms.Algorithm, Runtime, Union{Variable{I, J, O}, VariableInstance{O}} where {I, J}, O}} where O","page":"Algorithms","title":"Scruff.Algorithms.probability","text":"probability(alg::Algorithm, run::Runtime, item::Queryable{O}, value::O)::Union{Float64, Tuple{Float64, Float64}} where O\n\nReturn the probability that item has value or lower and upper probabilities.\n\nThe default implementation tries to use the more general probability of a query. If that fails, it uses the cpdf operation on the marginal of item.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.probability_bounds-Tuple{Scruff.Algorithms.Algorithm, Runtime, Union{Variable{I, J, O}, VariableInstance{O}} where {O, I, J}, Vector}","page":"Algorithms","title":"Scruff.Algorithms.probability_bounds","text":"probability_bounds(alg::Algorithm, run::Runtime, item::Queryable, range::Vector)::Tuple{Vector{Float64}, Vector{Float64}}\n\nFor an algorithm that produces lower and upper bounds, return vectors of lower and upper bounds on probabilities for values in the range.\n\nThe range is important for computing the bounds, because it is assumed that values outside the range have probability zero.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.refine-Tuple{Scruff.Algorithms.IterativeAlgorithm, InstantRuntime}","page":"Algorithms","title":"Scruff.Algorithms.refine","text":"refine(algorithm::IterativeAlgorithm, runtime::InstantRuntime)\n\nPerform the next iteration of the algorithm.\n\nUses the algorithm state stored in runtime and stores the next state in runtime.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.rejection_proposal-Tuple{Runtime, VariableInstance}","page":"Algorithms","title":"Scruff.Algorithms.rejection_proposal","text":"rejection_proposal(::Runtime, instance::VariableInstance, parent_values::Tuple)\n\nReturn a proposer and scorer to implement standard rejection sampling from the prior. It proposes a value for the instance from its sfunc, and scores it by the evidence, if any.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.retrieve_values_from_instant_runtime!-Union{Tuple{T}, Tuple{DynamicRuntime{T}, InstantRuntime}} where T","page":"Algorithms","title":"Scruff.Algorithms.retrieve_values_from_instant_runtime!","text":"retrieve_values_from_instant_runtime!(dynrun::DynamicRuntime, instrun::InstantRuntime)\n\nRetrieve values in a dynamic runtime from an instant runtime constructed\nusing `instant_runtime_from_instances`.\n\n\n\n\n\n","category":"method"},{"location":"lib/algorithms/#Scruff.Algorithms.variance-Tuple{Scruff.Algorithms.Algorithm, Runtime, Union{Variable{I, J, O}, VariableInstance{O}} where {O, I, J}}","page":"Algorithms","title":"Scruff.Algorithms.variance","text":"variance(alg::Algorithm, runtime::Runtime, item::Queryable)::Float64\n\nReturn the variance of item.\n\n\n\n\n\n","category":"method"}]
}
